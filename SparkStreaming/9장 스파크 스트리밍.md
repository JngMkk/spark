# 9장 스파크 스트리밍

```
스파크 스트리밍의 미니배치 개념을 사용해 특정 시간 간격 내에 유입된 데이터 블록을 RDD로 구성함.
이렇게 일괄 처리 기능을 실시간 데이터에 적용할 수 있음.

스파크는 다양한 외부 시스템 데이터를 스파크 스트리밍 job으로 입수할 수 있음.
여기서 말하는 외부 시스템은 단순한 파일 시스템이나 TCP/IP 접속 이외에도
카프카, 플럼, 트위터, 아마존 Kinesis 같은 분산 시스템을 의미함.
스파크 스트리밍은 각 데이터 소스별로 별도의 리시버를 제공함(일부 데이터 소스는 리시버 없이도 데이터를 입수할 수 있음)
각 리시버에는 해당 데이터 소스에 연결하고 데이터를 읽어 들여 스파크 스트리밍에 전달하는 로직이 구현되어 있음.
스파크 스트리밍은 리시버가 읽어 들인 데이터를 미니배치 RDD로 (주기당 하나씩) 분할하며,
스파크 애플리케이션은 이 미니배치 RDD를 애플리케이션에 구현된 로직에 따라 처리함.
미니배치를 처리하는 로직에는 머신 러닝이나 SQL 같은 스파크 API의 모든 기능을 자유롭게 적용할 수 있음.
미니배치를 처리한 결과는 파일시스템이나 관계형 데이터베이스 또는 다른 분산 시스템으로 내보낼 수 있음.

실시간 이벤트 처리는 궁극적인 목표이지만 항상 다양한 시나리오에서 해당 목표를 달성하는 것은 매우 어려움.
해당 처리 방식을 보증한다는 장점이 구현의 복잡성보다 큰 경우에는 정확히 한 번만 처리해야 하는 속성과 타협해야 함

구축하려는 사용 사례를 조사해 어떤 방식이 합리적으로 폭넓게 수행할 수 있고,
성능과 정확성이 허용 가능한 레벨인지 확인해야 함.
```

- 실시간 스트리밍 데이터 처리는 세 가지의 필수 처리 방식으로 분류할 수 있음.
  - 최소 한 번 처리
  - 최대 한 번 처리
  - 정확히 한 번 처리



#### 최소 한 번 처리

```
이벤트가 실제로 처리되고 결과가 어딘가에 저장된 후에 수신된 마지막 이벤트의 위치를 저장하는 메커니즘이 포함돼 있음.
실패가 발생해 컨슈머가 재시작되면 컨슈머는 이전 이벤트를 다시 읽고 처리함.
그러나 수신된 이벤트가 처리되지 않았거나 부분적으로 처리되지 않는다는 보장이 없기 때문에
이벤트를 다시 처리할 때 잠재적인 중복이 발생할 수 있으므로 이벤트가 최소 한 번만 처리되는 동작 방식을 필요로 함.

최소 한 번 처리 방식은 현재 값을 보여주는 순간적인 티커 또는 측정을 변경하는 모든 애플리케이션에 이상적임.
또한 누적 합계, 개수, 집계 정확성과 관련된 의존성(sum, groupby 등)은
중복 이벤트로 인해 잘못된 결과가 발생하기 때문에 해당 처리의 사용 사례에 적합하지 않음.

컨슈머의 연산 순서 : 결과 저장 -> 오프셋 저장

장애가 생겨 컨슈머가 재시작할 때 이벤트는 이미 처리됐지만 오프셋은 저장되지 않았기 때문에
컨슈머는 저장된 이전 오프셋에서 읽으면서 중복이 발생함.
```



#### 최대 한 번 처리

```
이벤트가 실제로 처리되기 전에 수신된 마지막 이벤트의 위치를 저장하는 메커니즘을 포함하고,
결과를 어딘가에서 저장시켜 실패가 발생하더라도 컨슈머가 재시작되면 컨슈머는 이전 이벤트는 읽지 않음.
그러나 수신된 이벤트가 모두 처리됐다는 보장이 없어서 다시 읽으려 하지 않기 때문에 이벤트가 잠재적으로 손실될 수 있음.
이로 인해 이벤트가 한 번만 처리되거나 전혀 처리되지 않을 수 있음.

최대 한 번 처리 방식은 현재 값을 보여주기 위해 순간적인 티커나 측정을 변경하는 모든 애플리케이션에 이상적임.
또한 누적 합계, 개수, 기타 집계뿐 아니라 정확도가 필수가 아니며 모든 이벤트를 꼭 필요로 하는 애플리케이션에 적합함.
모든 이벤트가 손실된다는 것은 잘못된 결과이거나 누락된 결과에서 발생한 것임.

컨슈머의 연산 순서 : 오프셋 저장 -> 결과 저장

장애가 생겨 컨슈머가 재시작할 때 이벤트는 처리되지 않았지만 오프셋은 저장되기 때문에
컨슈머는 저장된 오프셋을 읽어 소비될 이벤트의 차이가 발생될 수 있음.
```



#### 정확히 한 번 처리

```
최소 한 번 방식과 유사.
이벤트가 실제로 처리되고 어딘가에 저장된 후에만 수신된 마지막 이벤트의 위치를 저장하는 메커니즘을 포함함.
장애가 발생해 컨슈머가 재시작하면 컨슈머는 이전 이벤트를 다시 읽고 처리함.
그러나 수신된 이벤트가 전혀 처리되지 않았거나 부분적으로 처리됐다는 보장이 없기 때문에
이벤트를 다시 가져올 때 잠재적인 중복이 발생함.
그러나 최소 한 번 패러다임과 달리 중복이벤트는 처리되지 않고 제거되기 때문에 정확히 한 번 처리 방식이라 함.

정확히 한 번 처리 방식은 정확한 개수, 집계, 일반적으로 모든 이벤트가 한 번만 처리되고
확실하게 한 번(손실 없이) 처리해야 하는 애플리케이션에 적합함.

컨슈머의 연산 순서 : 결과 저장 -> 오프셋 저장

장애가 발생해 컨슈머가 재시작할 때 이벤트는 이미 처리됐지만 오프셋은 저장되지 않았기 때문에
컨슈머는 저장된 이전 오프셋에서 읽어 중복이 발생될 수 있음.
컨슈머가 중복 이벤트를 제거하기 때문에 한 번만 처리됨.
```

- 어떻게 중복을 제거하는가 ?
  - 멱등성 업데이트
  - 트랜잭션 업데이트



###### 멱등성 업데이트

```
멱등성 업데이트에 생성된 고유 ID/키를 기반으로 결과를 저장하는 작업이 포함돼 있음.
따라서 중복이 발생한 경우 생성된 고유 ID/키가 이미 결과에 있을 것임.
그래서 컨슈머가 결과를 업데이트하지 않고 중복을 제거할 수 있음.
고유한 키를 생성하는 것이 항상 가능하지 않고 쉽지 않기 때문에 복잡함. 또한 컨슈머 측에서 추가적으로 처리해야 함.
또 다른 고려 사항은 결과와 오프셋에 대해 데이터베이스가 분리될 수 있다는 점.
```



###### 트랜잭션 업데이트

```
트랜잭션 시작과 트랜잭션 커밋 단계를 포함하는 배치에 결과를 저장하기 때문에
커밋이 일어난다는 것은 이벤트가 성공적으로 처리된다는 의미임을 알 수 있음.
따라서 중복 이벤트가 수신되면 결과를 업데이트하지 않고 제거할 수 있음.
트랜잭션 업데이트는 트랜잭션 데이터 저장소가 필요하기 때문에 멱등성 업데이트보다 훨씬 복잡함.
또 다른 고려 사항으로 결과와 오프셋을 저장하는 데이터베이스가 동일해야 한다는 점이 있음.
```

---



## 1. 스파크 스트리밍

```
스파크 스트리밍은 다른 기술에 비해 분명한 몇 가지 장점이 있음.
무엇보다도 스파크 스트리밍 API와 스파크 코어 API 간의 긴밀한 통합을 통해
실시간 분석 플랫폼과 배치 분석 플랫폼을 구현할 수 있음.
스파크 스트리밍은 스파크 ML과 Spark SQL뿐만 아니라 GraphX와도 통합할 수 있고,
독특하고 복잡한 많은 사용 사례를 처리할 수 있는 가장 강력한 스트림 처리 기술임.

스파크 스트리밍은 여러 입력 소스를 지원하며, 결과를 여러 싱크에 저장할 수 있음.
연속적으로 데이터 스트림을 소비한 다음 수집된 데이터를 마이크로 배치 형태로 처리하기 때문에
Flink, Heron(Storm), Samza 등은 이벤트를 최소 지연 시간으로 수집해 처리함.
마이크로 배치의 크기는 500밀리초 정도로 낮을 수 잇지만 일반적으로 그보다 낮을 수는 없음.

스트리밍 작업은 설정 별로 정기적인 시간 간격으로 이벤트 배치를 생성하고,
추가 처리를 위해 데이터의 마이크로 배치를 지정된 간격마다 전달하는 것임.
RDD를 처리할 때 SparkContext를 사용한 것처럼
스파크 스트리밍에는 스트리밍 작업/애플리케이션의 주요 진입점인 StreamingContext가 있음.
StreamingContext는 SparkContext에 의존함. 사실 SparkContext는 스트리밍 작업에서 직접 사용될 수 있음.
둘은 비슷하지만 StreamingContext는 애플리케이션이 배치 간격의 시간 간격이나 기간(밀리초 또는 분)을 지정하게 요구함.
SparkContext가 주요 시작 지점이고 태스크 스케줄링과 자원 관리가 SparkContext의 일부여서 StreamingContext는 로직을 재사용함.
```



#### StreamingContext

```
스트리밍의 주요 진입점이며,
RDD의 Dstream에서 체크 포인팅, 트랜스포메이션, 액션을 포함하는 스트리밍 애플리케이션을 처리함.

어떤 클러스터를 사용하든 반드시 코어를 두 개 이상 익스큐터에 할당해야 함.
스파크 스트리밍의 각 리시버가 입력 데이터 스트림을 처리하려면 코어(스레드)를 각각 한 개씩 사용해야 하며,
별도로 최소 코어 한 개 이상이 프로그램 연산을 수행하는 데 필요함.
ex. spark-shell --master local[4]
```



###### StreamingContext 생성

1. 기존 SparkContext를 사용해 StreamingContext를 생성

   ```scala
   StreamingContext(sparkContext: SparkContext, batchDuration: Duration)
   
   val ssc = new StreamingContext(sc, Seconds(10))
   ```

2. 새로운 SparkContext를 생성하는 데 필요한 설정을 제공해 StreamingContext를 생성

   ```scala
   StreamingContext(conf: SparkConf, batchDuration: Duration)
   
   val conf = new SparkConf().setMaster("local[1]").setAppName("TextStreams")
   val ssc = new StreamingContext(conf, Seconds(10))
   ```

3. 체크 포인팅 데이터에서 StreamingContext를 재생성하거나

   새로운 StreamingContext를 생성하기 위해 사용되는 getOrCreate()를 사용.

   지정된 checkpointPath에 체크 포인팅 데이터가 존재하면 체크포인팅 데이터에서 StreamingContext가 재생성됨.

   데이터가 존재하지 않으면 CreatingFunc를 호출해 StreamingContext를 생성.

   ```scala
   def getOrCreate(
   	checkpointPath: String,
       creatingFunc: () => StreamingContext,
       hadoopConf: Configuration = SparkHadoopUtil.get.conf,
       createOnError: Boolean = false
   ): StreamingContext
   ```



###### StreamingContext 시작

```
start 메소드를 호출하면 StreamingContext를 사용해 정의된 스트림 실행을 시작함.
기본적으로 전체 스트리밍 애플리케이션이 시작됨.

지금까지 생성한 DStream들을 평가하고, 리시버를 시작한 후 DStream 연산을 수행함.
스파크 셸에서는 이 명령만 실행해도 애플리케이션의 스트리밍 처리를 시작하며, 다른 명령은 필요하지 않음.
리시버는 별도의 스레드에서 구동하기 때문에 스트리밍 처리가 시작되며
여전히 스파크 셸에 다른 명령을 입력하고, 병렬로 실행할 수 있음.

동일한 SparkContext 객체를 사용해 StreamingContext 인스턴스를 여러 개 생성할 수 있음.
하지만 동일 JVM에서는 StreamingContext를 한 번에 하나 이상 시작할 수 없음.

스파크 독립형 애플리케이션에서도 스파크 셸과 마찬가지로 start 메서드를 호출해 스트리밍 컨텍스트와 리시버를 시작함.
하지만 awaitTermination 메서드를 이어서 호출하지 않으면 리시버 스레드를 시작해도 드라이버의 메인 스레드가 종료됨.
awaitTermination 메서드는 스파크 스트리밍의 계산 작업을 종료할 때까지 스파크 애플리케이션을 대기시킴.
또는 awaitTerminationOrTimeout(밀리초 단위 제한 시간) 메서드를 사용할 수도 있음.
이 메서드는 애플리케이션의 대기 시간을 지정된 값으로 제한함.
스트리밍 계산이 제한 시간을 초과할 때는 false를 반환하며, 제한 시간 내에 계산을 완료할 때는 true를 반환함.
```

```scala
def start(): Unit

ssc.start()
```



###### StreamingContext 중지

```
StreamingContext를 중지하면 모든 처리는 멈춤.
애플리케이션을 재시작하려면 새로운 StreamingContext를 재생성하고 start를 호출해야 함.

인수를 전달하지 않으면 spark.streaming.stopSparkContextByDefault 매개변수에 설정된 값(true) 사용.
```

1. 즉시 스트림 실행 중지 (수신된 모든 데이터가 처리될 때까지 기다리지 않음)

   ```scala
   def stop(stopSaprkContext: Boolean)
   
   ssc.stop(false)
   ```

2. 스트림 실행을 중지. 수신된 모든 데이터가 처리됐는지 확인하는 옵션을 사용할 수도 있음

   ```scala
   def stop(stopSparkContext: Boolean, stopGracefully: Boolean)
   
   ssc.stop(true, true)
   ```

---



#### 입력 스트림

```
StreamingContext를 사용해서 생성할 수 있는 여러 타입의 입력 스트림
```



###### receiverStream ([참고](https://spark.apache.org/docs/latest/streaming-custom-receivers.html))

```
임의로 사용자가 구현한 수신기로서 입력 스트림을 생성. 사용 사례에 맞게 사용자가 정의할 수 있음.
```

```scala
def receiverStream[T: ClassTag](receiver: Receiver[T]): ReceiverInputDstream[T]
```



###### socketTextStream

```
TCP 소스인 '호스트이름:포트'에서 입력 스트림을 생성함.
TCP 소켓으로 데이터가 수신되고 수신된 바이트는 \n 구분자 라인으로 인코딩된 UTF-8로 해석됨.
StorageLevel을 선택 인자로 지정할 수 있음.(기본 값: StorageLevel.MEMORY_AND_DISK_SER_2).
이는 복제 계수를 2로 설정하고 RDD를 메모리와 디스크에 저장한다는 의미.
StorageLevel은 데이터가 보관될 위치와 데이터 복제 여부를 결정함.
```

```scala
def socketTextStream(hostname: String, port: Int,
                    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2): ReceiverInputDStream[String]
```



###### rawSocketStream

```
네트워크 소스인 '호스트이름:포트'에서 입력 스트림을 생성.
그래서 데이터는 역직렬화된 블록(스파크의 serializer를 사용해 직렬화됨)으로 수신되고
직렬화된 블록을 역직렬화하지 않고 블록 관리자로 바로 저장될 수 있음.
이는 데이터를 수신하는 가장 효율적인 방법.
```

```scala
def rawSocketStream[T: ClassTag](hostname: String, port: Int,
                                storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2): ReceiverInputDStream[T]
```



###### fileStream

```
메서드의 타입 매개변수로 키의 클래스 타입과 값을 클래스 타입,
HDFS 파일을 읽는 데 사용할 입력 포맷의 클래스 타입(하둡의 NewInputFormat 클래스를 상속한 하위 클래스)을 지정해야 함.
지정된 키 타입과 값 타입의 튜플을 요소로 포함한 DStream 반환.

타입 매개변수 외에 파일을 읽어 들일 폴더 경로를 전달해야 하며, 다음 선택 인수들을 추가로 지정할 수 있음
	- filter: 각 Path 객체(하둡에서 파일을 표현하는 클래스)별로 해당 파일의 처리 여부를 판단
				(함수는 Boolean 타입의 값을 반환해야 함)
	- newFilesOnly 플래그: 모니터링 폴더 아래에 새로 생성된 파일만 처리할지,
							아니면 폴더의 모든 파일을 처리할지 지정.
	- 하둡 Configuration 객체: HDFS 파일을 읽는 데 필요한 추가 옵션들을 설정.

새로운 파일에 대한 하둡 호환 파일 시스템을 모니터링하고
주어진 (키-값) 타입과 입력 포맷을 사용해 파일을 읽는 입력 스트림을 작성함.
동일한 파일 시스템에서는 파일을 다른 위치에서 이동시켜 모니터링되는 디렉터리에 저장해야 함.
.으로 시작하는 파일 이름은 무시되는데, 이는 모니터링되는 디렉터리에서 이동된 파일 이름에 대한 확실한 선택임.
원자적 파일 이름 변경 함수를 호출해 실제 사용할 수 있는 파일 이름으로 변경할 수 있음.
따라서 fileStream은 해당 파일 호출을 통해 파일 이름을 처리할 수 있음.
```

```scala
def fileStream[K: ClassTag, V: ClassTag, F <: NewInputForamt[K, V]: ClassTag](directory: String): InputDStream[(K, V)]
```



###### textFileStream

```
새로운 파일에 대한 하둡 호환 파일 시스템을 모니터링하고 해당 파일을 텍스트 파일로 읽는 입력 스트림 생성
(LongWritable을 키로, Text를 값으로, TextInputForamt을 입력 포맷으로 사용함)
파일은 동일한 파일 시스템의 다른 위치에서 이동시켜 모니터링될 디렉터리로 저장해야 함.
.으로 시작되는 파일 이름은 무시함
```

```scala
def textFileStream(directory: String): Dstream[String]
```

- 예시

  ```scala
  import org.apache.spark._
  import org.apache.spark.streaming._
  
  val ssc = new StreamingContext(sc, Seconds(10))
  val filestream = ssc.textFileStream("streamfiles")
  filestream.foreachRDD(rdd => {println(rdd.count())})
  ssc.start
  ```



###### binaryRecordsStream

```
이진 파일에서 특정 크기의 레코드를 읽어 들여(폴더 이름과 레코드 크기를 인수로 전달)
바이트 배열(Array[byte])로 구성된 DStream을 반환함.

새로운 파일에 대한 하둡 호환 파일 시스템을 모니터링하고
해당 파일을 레코드 당 고정 길이로 가정하고 레코드 당 1바이트 배열을 생성하는 flat 바이너리 파일로 읽음
파일은 동일한 파일 시스템의 다른 위치에서 이동시켜 모니터링될 디렉터리로 저장해야 함.
.으로 시작되는 파일 이름은 무시함
```

```scala
def binaryRecordsStream(directory: String, recordLength: Int): Dstream[Array[Byte]]
```



###### queueStream

```
RDD 큐에서 입력 스트림을 생성함. 각 배치는 큐에서 리턴하는 하나 또는 모든 RDD를 처리함.
```

```scala
def queueStream[T: ClassTag](queue: Queue[RDD[T]], oneAtATime: Boolean = true): InputDstream[T]
```

---



## 2. 불연속 스트림(이산 스트림)

```
스파크 스트리밍은 불연속 스트림 또는 DStream이라는 추상화를 기반으로 생성됨.
DStream은 RDD 시퀀스로 표현되며, 개별 시간 간격마다 개별 RDD가 생성됨.
DStream은 비순환 방향 그래프(DAG)와 같은 유사한 개념을 사용해 일반 RDD와 비슷한 방식으로 처리할 수 있음.
일반 RDD 처리와 마찬가지로 실행 계획의 일부인 트랜스포메이션과 액션을 사용해 DStream을 처리할 수 있음.

DStream은 본질적으로 끊임없는 데이터 스트림을 마이크로 배치라 알려진 작은 청크로 나눔.
마이크로 배치는 시간 간격을 기반으로 하고 각각의 마이크로 배치를 일반 RDD로 처리될 수 있는 RDD로 구체화함.
개별 마이크로 배치는 독립적으로 처리되고 마이크로 배치 간에 상태를 유지하지 않기 때문에 본질적으로 무상태 처리를 진행함.
배치 처리 간격이 5초라 가정하면 이벤트가 소비되는 동안 실시간과 마이크로 배치는 매 5초 간격으로 생성되고,
마이크로 배치는 추가적인 처리를 하도록 RDD로 전달함.
스파크 스트리밍의 주요 장점 중 하나는 이벤트를 마이크로 배치로 처리하는 데 사용된다는 점.
마이크로 배치는 나머지 아키텍처와 완벽히 통합할 수 있도록 제공되는 API를 사용해 스파크에 밀접하게 통합될 수 있음.
마이크로 배치가 생성되면 RDD로 바뀜. 즉 스파크 API를 활용해 원할하게 처리됨을 의미함.

스트리밍 애플리케이션을 작성하는 과정
	1. SparkContext에서 StreamingContext 생성
	2. StreamingContext에서 DStream 생성
	3. 각 RDD에 적용될 수 있는 트랜스포메이션과 액션을 제공
	4. 마지막으로 StreamingContext에서 start()를 호출해서 스트리밍 애플리케이션 시작
	   스트리밍 애플리케이션은 실시간 이벤트를 소비하고 처리하는 전체 프로세스를 시작
	   
스트리밍 애플리케이션이 시작되면 더 이상 연산을 추가할 수 없음.
중지된 컨텍스트를 재시작할 수 없으며, 필요성이 있다면 새로운 스트리밍 컨텍스트를 생성해야 함.

textFileStream 메서드 예)

StreamingContext의 textFileStream 메서드를 사용해 파일의 텍스트 데이터를 스트리밍으로 직접 전달할 수 있음.
textFileStream 메서드는 지정된 디렉터리를 모니터링하고, 디렉터리에 새로 생성된 파일을 개별적으로 읽어 들임.
메서드에는 HDFS, 아마존 S3, GlusterFS, 로컬 디렉터리 등 하둡과 호환되는 모든 유형의 디렉터리를 지정할 수 있고,
다른 인수는 없음.

textFileStream 메서드가 새로 생성된 파일을 읽어 들인다는 것은
StreamingContext를 시작할 시점에 이미 폴더에 있던 파일은 처리하지 않는다는 것을 의미함.
또 이 파일에 데이터를 추가해도 읽어 들이지 않음.
다시 말해 textFileStream 메서드는 스트리밍 처리를 시작한 시점 이후에 폴더로 복사된 파일들만 처리함.

textFileStream 메서드는 DStream 클래스의 인스턴스를 반환함.
DStream은 스파크 스트리밍의 기본 추상화 객체로 입력 데이터 스트림에서 주기적으로 생성하는 일련의 RDD 시퀀스를 표현함.
DStream은 RDD와 마찬가지로 지연 평가 됨.
따라서 textFileStream으로 DStream 객체를 생성한 시점에서는 아무 일도 일어나지 않음.
스트리밍 컨텍스트를 시작하면 그때부터 RDD가 실제로 유입됨.
```

- DStream 클래스의 가장 중요한 변수인 HashMap[Time, RDD] 쌍을 보여주는 소스 코드

  ```scala
  class DStream[T: ClassTag](var ssc: StreamingContext)
  
  // DStream의 RDD 해시맵
  var generatedRDDs = new HashMap[Time, RDD[T]]()
  ```



#### 트랜스포메이션

```
DStream의 트랜스포메이션은 스파크 코어 RDD에 적용되는 트랜스포메이션과 유사함.
DStream은 RDD로 구성돼 있기 때문에 각 RDD에 트랜스포메이션도 적용돼 RDD를 트랜스포메이션이 적용된 RDD로 생성함.
그 다음 트랜스포메이션이 적용된 DStream이 생성됨. 모든 트랜스포메이션은 특정 DStream 파생 클래스를 생성함.
```



###### 트랜스포메이션 타입

| 트랜스포메이션                   | 의미                                                         |
| -------------------------------- | ------------------------------------------------------------ |
| map(func)                        | DStream의 각 엘리먼트에 적용하고 하나의 새로운 DStream 리턴  |
| flatMap(func)                    | 각 엘리먼트에 flatMap 적용. 각 입력마다 여러 개의 출력 항목 생성 |
| filter(func)                     | DStream의 레코드를 필터링해서 하나의 새로운 DStream 리턴     |
| repartition(numPartitions)       | 병렬 처리를 변경하기 위해 데이터를 재분산해서<br>파티션의 개수가 많아지거나 적어짐 |
| union(otherStream)               | 2개의 DStream의 엘리먼트를 결합해 하나의 새로운 DStream을 리턴 |
| count()                          | 각 RDD 엘리먼트 개수를 계산해 새로운 DStream 리턴            |
| reduce(func)                     | 각 RDD 엘리먼트에 reduce 함수를 적용해 새로운 DStream 리턴   |
| countByValue()                   | 각 키의 빈도를 계산하고 (key, long) 쌍을 갖는 새로운 DSteam 리턴 |
| reduceByKey(func, [numTasks])    | 소스 DStream의 RDD에서 키를 기준으로 데이터를 집계하고<br>(키, 값) 쌍의 새로운 DStream 리턴 |
| join(otherStream, [numTasks])    | (K, V)와 (K, W) 쌍의 두 DStream을 조인하고<br>두 DStream의 값을 결합해 (K, (V, W)) 쌍의 새로운 DStream 리턴 |
| cogroup(otherStream, [numTasks]) | (K, V)와 (K, W) 쌍의 DStream에서 호출될 때<br>(K, Seq[V], Seq[W]) 튜플의 새로운 DStream 리턴 |
| transform(func)                  | 각 RDD에 트랜스포메이션 함수를 적용하고 새로운 DStream 리턴  |
| updateStateByKey(func)           | 키의 이전 상태와 키의 새로운 값에 주어진 함수를 적용해<br>각 키 상태 변경. 일반적으로 스테이트 머신을 유지,보수하기 위해 사용 |



#### 윈도우 연산

```
스파크 스트리밍은 윈도우 처리 기능을 제공하고 이벤트의 슬라이딩 윈도우에 트랜스포메이션을 적용할 수 있음.
주어진 간격으로 슬라이딩 윈도우를 생성할 수 있음.
윈도우는 원시 DStream을 이동할 때마다 주어진 윈도우 길이만큼 원시 RDD가 결합돼 윈도우 DStream이 생성됨.

윈도우에 대해 지정해야 하는 두 개의 파라미터
	- 윈도우 길이 : 윈도우로 간주되는 간격의 길이 지정
	- 슬라이딩 간격 : 윈도우를 만드는 간격

윈도 연산은 미니배치의 슬라이딩 윈도를 기반으로 수행함.
스파크 스트리밍은 슬라이딩 윈도의 길이와 이동 거리(즉, 윈도 데이터를 얼마나 자주 계산할지)를 바탕으로 윈도 DStream을 생성함.
슬라이딩 윈도의 길이와 이동 거리는 반드시 미니배치 주기의 배수여야 함.
```



###### 윈도우 연산

```
ByKey가 포함된 함수들은 Pair DStream에서만 사용할 수 있음.

window(windowLength, [slideInterval])
	길이가 windowLength인 슬라이딩 윈도 내 유입된 DStream 요소들을 slideInterval 주기마다 RDD 형태로 생성
	slideInterval을 지정하지 않으면 미니배치 주기를 기본 값으로 사용

countByWindow(windowLength, slideInterval)
	길이가 windowLength인 슬라이딩 윈도 내 유입된 DStream 요소들을 slideInterval 주기마다 모아서 개수를 집계하고,
	그 결과를 RDD에 담아 생성함.

countByValueAndWindow(windowLength, slideInterval, [numTasks])
	길이가 windowLength이고 이동 거리가 slideInterval인 슬라이딩 윈도 내 유입된 요소의 고유값별로 개수를 집계함.
	numTasks로 결과 RDD에 적용할 파티션 개수를 변경할 수 있음.
	각 키의 빈도를 계산하고 지정된 슬라이딩 윈도우에서 (키, long 타입의 값) 쌍으로 구성된 새로운 DStream 리턴.
	
reduceByWindow(func, windowLength, slideInterval)
	길이가 windowLength인 슬라이딩 윈도우를 생성한 후
	slideInterval 주기마다 reduceFunc 함수에 전달해 단일 값으로 리듀스하고, 그 결과를 RDD에 담아 생성.
	소스 DStream의 각 엘리먼트에 reduce 함수를 적용해 하나의 새로운 DStream 리턴
	
reduceByWindow(func, invFunc, windowLength, slideInterval)
	길이가 windowLength인 슬라이딩 윈도에 새로 유입된 DStream 요소들을 slideInterval 주기마다
	reduceFunc 함수에 전달해 단일 값으로 리듀스함.
	이와 동시에 슬라이딩 윈도를 벗어난 기존 요소들을 역리듀스 함수로 전달해
	reduceFunc에서 리듀스한 단일 값에서 제외한 결과를 RDD에 담아 생성함.
	이 메서드는 역리듀스 함수를 사용하지 않는 reduceByWindow보다 더 효율적임.

reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks])
	리듀스 함수와 윈도 길이 지정함.
	윈도의 이동 거리를 지정해 미니배치 주기와 이동 거리를 다르게 설정할 수도 있음.
	(이동 거리를 지정하지 않으면 기본 값으로 미니배치 주기를 사용)

	소스 DStream의 RDD에 적용된 윈도우에서 키로 데이터를 집계하고
	(키, 값) 쌍으로 구성된 하나의 새로운 DStream 리턴. 제공된 함수 func를 통해 계산됨.

reduceByKeyAndWindow(func, invFunc, windowLength, [slideInterval], [numTasks], [filterFunc])
	리듀스 함수만 전달하는 reduceByKeyAndWindow와 기능은 동일하지만,
	역리듀스 함수를 사용해 슬라이딩 윈도를 벗어난 요소들을 더 효율적으로 제외할 수 있음.
	선택 인수인 filterFunc 함수로 결과 DStream에 남을 키-값 쌍의 조건을 지정할 수 있음.
	
	소스 DStream의 RDD에 적용된 윈도우에서 키를 기준으로 데이터를 집계하고
	(키, 값) 쌍으로 구성된 하나의 새로운 DStream 리턴.
	슬라이딩 윈도우의 시작 부분에서 수행할 계산을 제공하는 invFunc가 있음.
	
groupByKeyAndWindow(windowLength, [slideInterval], [numTasks/partitioner])
	길이가 windowLength이고 이동 거리가 slideInterval인 슬라이딩 윈도 내 유입된 요소들을 키별로 그룹핑함.
	결과 RDD에 적용할 파티션 개수 또는 Partitioner를 선택 인수로 지정할 수 있음.
```

```scala
import org.apache.log4j.Logger
import org.apache.log4j.Level

import java.util.Date
import org.apache.spark._
import org.apache.spark.streaming._
import org.apache.spark.streaming.twitter._
import twitter4j.auth.OAuthAuthorization
import twitter4j.conf.ConfigurationBuilder

def createTwitterStreamContext(): StreamingContext = {
    val ssc = new StreamingContext(sc, Seconds(5))
    val twitterStream = TwitterUtils.createStream(ssc, None)
    val wordStream = twitterStream.flatMap(x => x.getText().split(" "))
    val aggStream = twitterStream.flatMap(x => x.getText.split(" ")).
        filter(_.startsWith("#")).map(x => (x, 1)).
        reduceByKeyAndWindow(_ + _, _ - _, Seconds(15), Seconds(10), 5)

    ssc.checkpoint("checkpoints")
    wordStream.checkpoint(Seconds(10))
    aggStream.checkpoint(Seconds(10))

    aggStream.foreachRDD((rdd, time) => {
        val count = rdd.count()
        if (count > 0) {
            val dt = new Date(time.milliseconds)
            println(s"\n\n$dt rddCount = $count\nTop 5 Words\n")
            val top5 = rdd.sortBy(_._2, ascending = false).take(5)
            top5.foreach {
                case (word, count) => println(s"[$word] - $count")
            }
        }
    })
    ssc
}

Logger.getLogger("org").setLevel(Level.OFF)

System.setProperty("twitter4j.oauth.consumerKey", "")
System.setProperty("twitter4j.oauth.consumerSecret", "")
System.setProperty("twitter4j.oauth.accessToken", "")
System.setProperty("twitter4j.oauth.accessTokenSecret", "")

val checkpoinDirectory = "checkpoints"
val ssc = StreamingContext.getOrCreate(checkpoinDirectory, createTwitterStreamContext _)

ssc.start()

ssc.stop(false)
```

---



## 3. 상태 저장 / 상태 비저장 트랜스포메이션

```
DStream에 대한 트랜스포메이션은 상태 비저장 트랜스포메이션과 상태 저장 트랜스포메이션의 두 가지 타입으로 그룹핑할 수 있음.

상태 비저장 트랜스포메이션에서는 데이터의 각 마이크로 배치가 이전 데이터 배치에 종속되지 않음.
따라서 이는 각 배치가 해당 배치 이전에 발생한 것과 독립적으로 자체 처리를 수행하는 상태 비저장 트랜스포메이션임.

상태 저장 트랜스포메이션에서는 데이터의 각 마이크로 배치가 이전 데이터 배치(부분 배치일 수도 있고 전체 배치일 수도 있음)에 종속적임.
따라서 각 배치에서 데이터를 계산할 때 각 배치는 해당 배치 이전에 발생한 배치 내용을 사용하는 상태 저장 트랜스포메이션임.
```



#### 상태 비저장 트랜스포메이션

```
상태 비저장 트랜스포메이션은 DStream의 각 RDD에 트랜스포메이션을 적용해 하나의 DStream을 다른 DStream으로 변환함.
map, flatMap, union, join, reduceByKey와 같은 트랜스포메이션은 모두 상태 비저장 트랜스포메이션임.
```



#### 상태 저장 트랜스포메이션

```
상태 저장 트랜스포메이션은 DStream에서 동작하지만 계산은 이전 처리 상태에 따라 달라짐.
countByValueAndWindow, reduceByKeyAndWindow, mapWithState,
updateStateByKey와 같은 연산은 모두 상태 저장 트랜스포메이션.
사실 윈도우 연산의 정의에 따르면 DStream의 윈도우 길이와 슬라이딩 간격을 추적해야 하기 때문에
모든 윈도우 기반 트랜스포메이션은 상태 저장 트랜스포메이션임.
```



###### updateStateByKey

```
두 메서드 모두 PairDStreamFunctions 클래스로 사용할 수 있음.
다시 말해 키-값 튜플로 구성된 Pair DStream에서만 이 메서드를 사용할 수 있다는 의미임.
그러므로 메서드를 호출하기 전에 먼저 Pair DStream을 생성해야 함.

updateStateByKey는 두 가지 기본 버전을 제공함. 첫 번째 버전은 DStream 값만 처리함.
두 번째 버전은 DStream의 키와 값을 한꺼번에 처리하며, 키를 변경할 수도 있음.
두 버전 모두 각 키의 상태 값을 포함한 새로운 State DStream을 반환함.

updateStateByKey 메서드에 전달할 함수 시그니처: (Seq[V], Option[S]) => Option[S]

함수의 첫 번째 인수에는 현재 미니배치에 유입된 각 키의 Seq 객체가 전달됨.
두 번째 인수에는 키의 상태 값이 Option으로 전달됨.
해당 키의 상태를 아직 계산한 적이 없으면 Option 객체는 None을 반환함.
반대로 키의 상태를 계산한 적은 있지만, 해당 키 값이 현재 미니배치에 유입되지 않은 경우 첫 번째 인수에 빈 Seq 객체가 전달됨.
어떤 경우든 이 함수는 각 키의 새로운 상태 값을 반환해야 함.

또 updateStateKey 메서드에는 결과 DStream에 사용할 파티션 개수나 Partitioner 객체를 선택 인수로 지정할 수 있음.
대량의 키와 상태 객체를 유지할 때는 적절한 파티셔닝이 중요함.
```



###### mapWithState

```
mapWithState 메서드는 기존 updateStateByKey 기능 및 성능을 상당히 개선함.
updateStateByKey와 차이점은 상태 값의 타입과 반환 값의 타입을 다르게 적용할 수 있다는 것임.

mapWithState 메서드는 StateSpec 클래스의 인스턴스만 인수로 받음.
StateSpec은 mapWithState를 설정할 매개변수를 구성하는 데 사용.
StateSpec 객체를 초기화하려면 StateSpec.function 메서드에 다음 시그니처 매핑 함수를 정의해서 전달해야 함.

([Time], KeyType, Option[ValueType], State[StateType]) => Option[MappedType]
첫 번째 인수인 Time 객체는 선택 인수이므로 함수 정의에서 제외할 수 있음.

StateSpec에 전달한 매핑 함수에는 updateStateByKey 메서드의 함수와 마찬가지로
각 키에 새로 유입된 값들과 해당 키의 기존 상태 값이 전달됨(키는 KeyType, 값은 ValueType, 상태 값은 StateType)
그러나 결과 DStream의 요소와 상태 값의 타입이 동일한 updateStateByKey와 달리
mapWithState의 매핑 함수는 상태 값과는 다른 MappedType을 반환할 수 있음.

매핑 함수의 네 번째 인수인 State는 각 키의 상태 값을 저장하는 객체로,
상태 값을 다룰 수 있는 여러 유용한 메서드를 제공함.
	- exists: 상태 값이 존재하면 true 반환
	- get: 상태 값을 가져옴
	- remove: 해당 키의 상태를 제거함
	- update: 해당 키의 상태 값을 갱신(또는 초기화)함.
	
StateSpec 객체에는 매핑 함수 외에도
파티션 개수, Partitioner 객체, 초기 상태 값을 담은 RDD, 제한 시간 등을 설정할 수 있음.
특히 초기 상태 값을 지정하는 기능을 잘 활용하면 종료된 스트리밍 작업을 재시작할 때도 종료 전 상태 값을 유지하고 재사용할 수 있음.
예를 들어 하루의 주식 시장을 마감할 때 고객 목록과 누적 거래액을 저장해 두면,
다음 날에는 전날의 마지막 상태부터 다시 시작해 거래액을 계속 누적할 수 있음.

제한 시간을 설정하면 스파크 스트리밍은 이 시간을 초과해 만료된 특정 상태 값을 삭제함.
고객이 접속한 세션의 만료 여부를 계산하는 데 이 기능을 사용할 수 있음.
동일한 기능을 updateStateByKey로 구현하려면, 매핑 함수에서 만료 여부를 직접 계산해야 함.
```

---



## 4. 체크 포인팅

```
실시간 스트리밍 애플리케이션은 어떠한 실패가 발생하더라도 오랫동안 실행돼야 하고 복원력이 있어야 함.
스파크 스트리밍은 실패로부터 복구할 수 있는 충분한 정보를 유지 관리하는 체크 포인팅 기능을 갖고 있음.

체크 포인팅이 필요한 두 가지 타입의 데이터가 있음.
	- 메타데이터 체크 포인팅
	- 데이터 체크 포인팅

체크 포인팅은 StreamingContext에서 checkpoint 함수를 호출해 활성화할 수 있음.

def checkpoint(directory: String)
	체크 포인팅 데이터가 제대로 저장될 디렉터리를 지정.
	해당 디렉터리는 HDFS와 같은 내결함성 파일 시스템이어야 함.
	
체크 포인팅 디렉터리가 설정되면 지정된 간격에 따라 해당 디렉터리에 DStream을 체크 포인팅할 수 있음.
```



###### 메타데이터 체크 포인팅

```
메타데이터 체크 포인팅은 스트리밍 연산을 정의하는 정보를 저장함.
해당 정보는 DAG로 표시돼 HDFS에 저장됨. 또한 실패가 발생하고 애플리케이션이 재시작하면 DAG를 복구할 수 있음.
스파크 드라이버가 HDFS에서 메타데이터를 읽고 재시작하여 다음 DAG를 재작성한 후 실패 이전의 모든 동작 상태를 복구함.

메타데이터에는 다음을 포함함
	- 설정: 스파크 스트리밍 애플리케이션을 만들 때 사용되는 설정
	- DStream 연산: 스트리밍 애플리케이션을 정의하는 DStream 연산 집합
	- 불완전한 배치: job이 대기 중이고 아직 완료되지 않은 배치
```



###### 데이터 체크포인팅

```
데이터 체크 포인팅은 실제로 RDD를 HDFS에 저장하기 때문에 스트리밍 애플리케이션에서 HDFS 저장이 실패하면
애플리케이션은 체크 포인팅이 지정된 RDD를 복구하고 중단됐던 위치에서 계속 진행함.
스트리밍 애플리케이션 복구는 데이터 체크 포인팅에 대한 좋은 사용 사례.
체크 포인팅은 재계산될 계보의 모든 부모 RDD를 기다릴 필요 없이 생성된 RDD를 인스턴스화함으로써
캐시 정리나 익스큐터 장애로 인해 일부 RDD가 손실될 때마다 더 나은 성능을 얻음.

체크 포인팅은 다음 요구 사항 중 하나를 가진 애플리케이션을 활성화해야 함
	- 상태 저장 트랜스포메이션 사용
		애플리케이션에서 updateStateByKey 또는 reduceByKeyAndWindow(역함수도 포함)가 사용되면
		주기적인 RDD 체크 포인팅이 가능하도록 체크 포인팅 디렉터리를 제공해야 함.
	- 애플리케이션을 실행하는 드라이버의 실패를 복구하기
		메타데이터 체크 포인팅은 진행 정보를 복구하기 위해 사용됨.

스트리밍 애플리케이션에서 상태 저장 트랜스포메이션을 사용하지 않으면 체크 포인팅 없이 애플리케이션을 실행할 수 있음.
RDD 체크 포인팅은 각 RDD에 대한 저장소 저장 비용이 발생함.
따라서 RDD가 체크 포인팅하는 배치의 처리 시간이 늘어날 수 있음.
따라서 성능 문제가 발생하지 않도록 체크 포인팅 간격을 신중하게 설정해야 함.
체크 포인팅을 너무 적게 사용하면 계보와 작업 크기가 커져 저장될 데이터의 양이 많아지기에 처리 지연이 발생할 수 있음.

RDD 체크 포인팅이 필요한 상태 저장 트랜스포메이션의 경우 기본 간격은 배치 간격의 배수인 10초 이상임.
```



###### 드라이버 실패 복구

```
드라이버 실패 복구는 기존 체크 포인팅에서 StreamingContext를 초기화하거나
새로운 StreamingContext를 생성하기 위해 StreamingContext.getOrCreate 함수를 사용함으로써 이뤄질 수 있음.

다음은 스트리밍 애플리케이션이 시작될 때 2가지 조건
	- 프로그램이 처음 시작될 때 새로운 StreamingContext를 생성하고 모든 스트림을 설정한 다음 start 함수를 호출해야 함.
	- 실패 후 프로그램이 재시작될 때 체크 포인팅 디렉터리의 체크 포인팅 데이터에서
	  StreamingContext를 초기화한 다음 start 함수를 호출해야 함.
```



###### 체크포인팅 데이터에서 StreamingContext 초기화 하는 예시

```scala
// getOrCreate 함수를 호출해 checkpointDir이 있는지 확인한 다음, 체크 포인팅 데이터에서 Context 재생성.
// 디렉터리가 존재하지 않으면(처음 실행되는 경우) createContext 함수가 호출돼 새로운 Context 생성.
val ssc = StreamingContext.getOrCreate(checkpointDir, createStreamContext _)
```

---



## 5. 스트리밍 플랫폼과의 상호운용성(아파치 카프카)

```
스파크 스트리밍은 현재 가장 널리 사용되는 메시징 플랫폼인 아파치 카프카와 매우 잘 통합돼 있음.
카프카 통합에는 몇 가지 접근 방식이 있고, 메커니즘은 시간이 지남에 따라 성능과 안정성을 향상시킬 수 있게 발전함.

스파크 스트리밍과 카프카를 통합하는 3가지 주요 접근 방식이 있음.
	- 수신기 기반 접근 방식
	- 다이렉트 스트림 접근 방식
	- 구조화 스트리밍
```



#### 수신기 기반 접근 방식

```
수신기 기반 접근 방식은 스파크와 카프카의 첫 번째 통합 방식이었음.
수신기 접근 방식에서 드라이버는 익스큐터에서 카프카 브로커의 고급 API를 사용해 데이터를 가져올 수 있는 수신자를 실행함.
수신자가 카프카 브로커에서 이벤트를 가져 오고 있기 때문에 수신자는 마지막 메시지의 오프셋을 주키퍼에 저장함.
주키퍼는 카프카 클러스터에서도 사용됨. 주요 측면은 WAL(Write Ahead Log)의 사용임.
수신자는 카프카에서 데이터를 소비하면서 WAL에 계속 저장함.(streaming.receiver.writeAheadLog.enable ture 지정해야 함)
따라서 문제가 발생해 익스큐터나 수신자가 손실되거나 재시작될 때 WAL을 사용해 이벤트를 복구하고 처리할 수 있음.
따라서 이 로그 기반 설계는 내구성과 일관성을 모두 제공함.
리시버 기반 접근 방식은 간혹 메시지 한 개를 여러 번 읽어 오기도 함.
데이터 유실을 방지하려고 WAL을 사용하는데 그만큼 계산 속도가 감소함.

각 수신기는 카프카 토픽에서 이벤트의 입력 DStream을 생성하고 주키퍼에 카프카 토픽, 브로커, 오프셋 등을 쿼리함.
수신자는 카프카 주키퍼 클러스터에서 토픽 오프셋 범위를 가져온 다음 주키퍼를 업데이트해 브로커에서 이벤트를 가져옴.

오랜 시간동안 동작하는 수신기는 애플리케이션이 확장되면서 작업 부하를 제대로 분배하지 못하면서 병렬 처리를 복잡하게 만듦.
저장 연산의 중복 문제와 함께 HDFS에 대한 의존도도 문제임.
정확히 한 번 처리 방식에서 필요한 신뢰성에 대해 말하면 멱등성 접근 방식만 동작할 것임.
트랜잭션 방식이 수신기 기반 접근에서 동작하지 않는 이유는
HDFS 위치나 주키퍼에서 오프셋 범위로 접근할 수 있다는 방법이 없다는 점임.
```



###### 수신기 기반 스트림 생성

```scala
def createStream(
	ssc: StreamingContext,
    // 주키퍼 쿼럼 (호스트이름:포트, 호스트이름:포트, ...)
    zkQuorum: String,
    // 컨슈머의 그룹 id
    groupId: String,
    // 소비할 (토픽 이름, 파티션 개수) 맵. 각 파티션은 자체 스레드에서 사용됨.
    topics: Map[String, Int],
    // default: StorageLevel.MEMORY_AND_DISK_SER_2
    storageLevel: StorageLevel = StorageLevel.MEMORY_AND_DISK_SER_2
): ReceiverInputDStream[(String, String)]
// 반환 값: (카프카 메시지 키, 카프카 메시지 값) DStream
```

```scala
val topicMap = topics.split(",").map((_, numThreads.toInt)).toMap
val lines = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap).map(_._2)
```



#### 다이렉트 스트림 접근 방식

```
범용 MQ가 아닌 카프카에서만 사용할 수 있는 방식.

다이렉트 스트림 접근 방식은 카프카 통합과 관련된 새로운 접근 방식이며,
드라이버를 사용해 브로커에 직접 연결하고 이벤트를 가져 오는 방식으로 동작함.
집중해서 살펴볼 부분은 다이렉트 스트림 API를 사용하는 것이므로
스파크 태스크는 카프카 토픽/파티션 대비 스파크 파티션 비율을 볼 때 1:1 비율로 동작한다는 점임.
다이렉트 스트림 접근 방식은 HDFS나 WAL에 대한 의존성 때문에 유연하지 않음.

오프셋으로 바로 접근할 수 있기 때문에 멱등성이나 트랜잭션 방식을 사용해 정확히 한 번만 처리할 수 있음.

수신자를 사용하지 않고 카프카 브로커에서 직접 메시지를 가져오는 입력 스트림을 생성함.
주키퍼 대신 스파크 체크포인팅 디렉터리에 오프셋을 저장함.
가져온 메시지의 오프셋이 없을 경우 auto.offset.reset 매개변수로 어떤 메시지부터 가져올지 지정할 수 있음.
(Map 매개변수에 같이 저장하면 됨)
이 값을 smallest로 설정하면 가장 작은 오프셋의 데이터부터 가져옴.
매개변수를 설정하지 않으면 가장 최신의 메시지를 가져옴.
입력 스트림은 카프카에서 가져온 각 메시지가 정확히 한 번 처리하는 트랜스포메이션에 포함되도록 보장할 수 있음.

다이렉트 스트림의 속성은 다음과 같음.
	- 수신자 없음: 다이렉트 스트림은 수신자를 사용하지 않고 직접 카프카에 쿼리함.
	- 오프셋: 다이렉트 스트림은 주키퍼를 사용해 오프셋을 저장하지 않으며, 사용된 오프셋은 스트림 자체에서 추적.
			 생성된 RDD에서 각 배치에 사용된 오프셋에 접근할 수 있음.
	- 실패 복구: 드라이버 실패에서 복구하려면 StreamingContext에서 체크 포인팅을 활성화해야 함.
	- 종단 간 의미 체계: 다이렉트 스트림은 모든 레코드를 효과적으로 수신하고
					  정확히 한 번 처리하는 트랜스포메이션을 사용할 수 있지만,
					  트랜스포메이션이 적용된 데이터가 정확히 한 번만 출력되는지 여부는 보장하지 않음.
```



###### 다이렉트 스트림 생성

> [카프카 설정 파라미터](https://kafka.apache.org/documentation.html#configuration)

```scala
def createDirectStream[
    K: ClassTag,				// 카프카 메시지 키의 K타입
    V: ClassTag,				// 카프카 메시지 값의 V타입
    KD <: Decoder[K]: ClassTag,	// 카프카 메시지 키 디코더의 KD 타입
    VD <: Decoder[V]: ClassTag,	// 카프카 메시지 값 디코더의 VD 타입
    R: ClassTag					// 메시지 핸들러에서 리턴하는 R타입
](
    ssc: StreamingContext,
    
    // 카프카 설정
    // host1:port1, host2:port2 형식으로 지정된 카프카 브로커(주키퍼 서버x)와 함께
    // "metadata.broker.list" 또는 "bootstrap.servers" 파라미터를 설정해야 함.
    KafkaParams: Map[String, String],
    
    // 스트림의 시작점(포함)을 정의하는 토픽/파티션 별 카프카 오프셋
    fromOffsets: Map[TopicAndPartition, Long],
    
    // 각 메시지와 메타데이터를 원하는 타입으로 변환하는 함수
    messageHandler: MessageAndMetadata[K, V] => R
): InputDStream[R]
// R 타입의 DStream 반환
```

```scala
val topicsSet = topics.split(",").toSet
val KafkaParams: Map[String, String] = Map("metadata.broker.list" -> brokers,
                                          "group.id" -> groupid)
val rawDstream = KafkaUtils.createDirectStream[
    String, String, StringDecoder, StringDecoder
](ssc, KafkaParams, topicsSet)
```



#### 구조화 스트리밍

> [구조화 스트리밍 참고](https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html)



###### 구조화 스트리밍에서 카프카 소스 스트림을 사용하는 방법 예

```scala
val ds1 = spark.
	readStream.
	format("Kafka").
	option("Kafka.bootstrap.servers", "host1:port1,host2:port2").
	option("subscribe", "topic1").
	load()

ds1.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
```



###### 더 많은 배치 분석 접근 방법을 원하는 경우 카프카 소스 스트림 대신 카프카 소스를 사용하는 방법 예

```scala
val ds1 = spark.
	read.
	format("Kafka").
	option("Kafka.bootstrap.servers", "host1:port1,host2:port2").
	option("subscribe", "topic1").
	load()

ds1.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)").as[(String, String)]
```



#### 카프카로 메시지 전송

```
스파크 스트리밍에서 카프카로 메시지를 전송하는 기능은 DStream의 foreachRDD 메서드로 구현할 수 있음.
이 메서드는 임의의 함수를 DStream의 각 RDD별로 실행함.

def foreachRDD(foreachFunc: RDD[T] => Unit): Unit
def foreachRDD(foreachFunc: (RDD[T], Time) => Unit): Unit

두 버전 모두 foreachFunc라는 단일 인수를 받음.
foreachFunc 함수는 RDD를 받고 Unit(자바의 void와 동일한 개념)을 반환.
두 번째 버전의 foreachFunc 함수에는 Time 객체를 전달하며, RDD 데이터가 유입된 시각을 함수 로직에 반영할 수 있음.

카프카에 메시지를 전송하려면 카프카의 Producer 객체를 사용해야 함.
Producer 객체는 카프카 브로커에 접속하고, KeyedMessage 객체의 형태로 구성한 메시지를 카프카 토픽으로 전송함.
카프카의 ProducerConifg 객체로 Producer를 설정하고 사용할 수 있음.

하지만 Producer 객체는 직렬화할 수 없다는 제약이 있음.
이 객체는 카프카 커넥션을 생성하며, 이 커넥션 객체를 직렬화 및 역직렬화해 다른 JVM에서 계속 사용하는 것은 사실살 불가능함.
따라서 Producer 객체를 생성하는 작업은 받드시 실행자에서 구동될 코드에 구현해야 함.
가장 단순한 해결책음 foreach 메서드 내에서 Producer 객체를 생성하는 것임.
또는 foreach 대신 foreachPartition 메서드를 사용해 RDD 파티션별로 Producer를 하나씩 생성할 수도 있음.
가장 좋은 방법은 싱글톤 객체를 생성해 JVM별로 Producer 객체를 하나씩만 초기화하는 것임.
```





---



## 6. 구조화 스트리밍

```
구조화 스트리밍은 스파크 SQL 엔진 위에 구축된 확장 가능하고 내결함성 스트림 처리 엔진.
이는 DStream 패러다임 및 스파크 스트리밍 API와 관련된 이슈가 아니라 스트림 처리와 계산이 배치 처리에 가까움.
구조화 스트리밍 엔진은 정확히 한 번 스트림 처리, 처리 결과에 대한 증분 업데이트, 집계 등과 같은 내용을 처리함.

또한 구조화 스트리밍 API는 스파크 스트리밍의 큰 이슈를 해결할 수 있는 방법을 제공함.
즉, 스파크 스트리밍은 들어오는 데이터를 마이크로 배치로 처리하고
수신 시간을 데이터로 분할하는 수단으로 사용하므로 실제 이벤트 시간을 고려하지 않음.
구조화 스트리밍을 사용하면 수신되는 데이터에서 이런 이벤트 시간을 지정해 최신 데이터가 자동으로 처리되게 할 수 있음.

구조화 스트리밍의 핵심 아이디어는 실시간 데이터 스트림 이벤트가 스트림에서 처리될 때
연속적으로 추가되는 무제한 테이블로 처리하는 것임.
그리고 일반적으로 배치 데이터를 갖고 처리하는 것처럼 무제한 테이블에서 계산과 SQL 쿼리를 실행할 수 있음.

DStream은 시간이 지나면서 많은 데이터를 처리하고 결과를 생성함.
따라서 무제한 입력 테이블은 결과 테이블을 생성하는 데 사용됨.
출력 또는 결과 테이블은 output이라고 하는 외부 싱크에 저장될 수 있음.

output은 저장되는 곳이고 다른 모드로 정의될 수 있음
	- 완료 모드: 업데이트된 전체 결과 테이블이 외부 저장소에 저장됨.
			    전체 테이블 저장을 처리하는 방법에 대한 결정은 저장소 커넥터에 달려 있음.
	- 추가 모드: 마지막 트리거 이후 결과 테이블에 추가된 모든 새로운 로우만 외부 저장소에 저장될 것.
				이는 결과 테이블의 기존 로우가 업데이트 되지 않아야 하는 쿼리에만 적용됨.
	- 업데이트 모드: 마지막 트리거 이후 결과 테이블에서 업데이트된 로우만 외부 저장소에 저장됨.
					해당 모드는 마지막 트리거 이후 업데이트된 로우만 출력한다는 점에서 완료 모드와 다름
					쿼리에 집계가 포함돼 있지 않으면 추가 모드와 동일함.
	
writeStream: DataStreamWriter 반환
	- trigger: 스트리밍 연산 수행 주기를 지정함.
				시간 주기는 ProcessingTime.create 함수로 설정함
	- format: 출력 포맷을 설정함. parquet, console, memory 등
	- foreach: 개별 Dataframe 계산을 수행하는 데 사용
				ForeachWriter 인터페이스를 구현한 클래스를 메서드 인수로 전달해야 함.
	- queryName: memory 포맷을 사용할 때 테이블 이름을 지정함.
```



###### 예시

```scala
val inputLines = spark.readStream.
    format("socket").
    option("host", "localhost").
    option("port", 9999).
    load()

// inputLines을 단어로 나눔
// as : def as[U: Encoder]: Dataset[U]
// Dataset 내용을 해석할 방법을 정의한 Encoder 객체를 전달해야 함
val words = inputLines.as[String].flatMap(_.split(" "))

// 단어 개수를 얻음
val wordCounts = words.groupBy("value").count()

val query = wordCounts.writeStream.outputMode("complete").format("console")

query.start()

/*
-------------------------------------------
Batch: 1
-------------------------------------------
+-----+-----+
|value|count|
+-----+-----+
|   my|    1|
|   hi|    1|
+-----+-----+
*/
```



#### 이벤트 시간과 지연 데이터 처리

```
이벤트 시간은 데이터 자체 내부의 시간임.
전통적인 스파크 스트리밍은 DStream 용도를 위한 수신 시간으로만 처리된 시간을 처리했지만,
이벤트 시간이 필요한 많은 애플리케이션에서 기존 기능만으로 충분치 않음.
예를 들어 해시 태그가 매분마다 트윗에 표시되는 횟수를 확인하려면
스파크가 이벤트를 수신할 시간이 아니라 데이터가 생성된 시간을 사용해야 함.
이벤트 시간이 섞여 있는 스트리밍 데이터에서 이벤트 시간을 얻으려면 이벤트 시간을 로우나 이벤트의 특정 컬럼으로 생각한다면
구조화 스트리밍에서는 해당 컬럼에서 이벤트 시간을 얻는 것이 매우 쉬워짐.
이를 통해 수신 시간이 아닌 이벤트 시간을 사용해 윈도우 기반 집계를 실행할 수 있음.

게다가 해당 모델은 이벤트 시간을 기반으로 예상보다 늦게 도착한 데이터를 자연스럽게 처리함.
스파크는 결과 테이블을 업데이트하기 때문에 지연된 데이터가 있다면 이전 집계를 업데이트할 뿐 아니라
중간 상태의 데이터 크기를 제한하기 위해 이전 집계를 정리할 수 있게 완전히 제어할 수 있음.
또한 워터마킹 이벤트 스트림을 지원함.
워터마킹 스트림을 사용하면 사용자는 지연 데이터의 임계값을 지정할 수 있고,
해당 데이터를 기반으로 스파크는 이전 상태를 정리할 수 있음.

워터마크를 사용하면 스파크는 현재 이벤트 시간을 추적하고 이벤트가 처리돼야 하는지
또는 지연 데이터를 수신할 수 있는지에 대한 임계값을 확인하고 처리할지 여부를 결정할 수 있음.
예를 들어 이벤트 시간이 eventTime으로 표시되고 늦게 도착하는 데이터의 임계 간격이
lateThreshold라 한다면 max(eventTime) - lateThreshold 간의 차이를 확인하고
시간 T에서 시작하는 특정 윈도우를 비교함. 따라서 스파크는 이벤트를 윈도우에서 처리할지 여부를 결정할 수 있음.
```



###### 구조화 스트리밍에 대한 이전 예 확장

> Timestamp를 입력 데이터의 일부로 활성화해 무제한 테이블에서 윈도 연산을 수행함으로써 결과를 생성할 수 있음.

```scala
import java.sql.Timestamp

// '호스트:포트'에 대한 커넥션에서 입력 라인 스트림을 의미하는 데이터 프레임 생성
val inputLines = spark.readStream.
    format("socket").
    option("host", "localhost").
    option("port", 9999).
    option("includeTimestamp", true).
    load()

// 타임스탬프를 포함한 라인을 단어로 나눔
// import spark.implicits._
val words = inputLines.as[(String, Timestamp)].
    flatMap(line => line._1.split(" ").map(word => (word, line._2))).toDF("word", "timestamp")

// 윈도우와 단어별로 그룹핑하고 각 그룹별로 단어 개수를 계산함.
val windowedCounts = words.withWatermark("timestamp", "10 seconds").
    groupBy(window('timestamp, "10 seconds", "10 seconds"), 'word).
    count().orderBy('window)

// 윈도우 안의 단어 개수를 콘솔에 출력하는 쿼리를 실행함.
val query = windowedCounts.writeStream.
    outputMode("complete").
    format("console").
    option("truncate", "false").
    start()

query.awaitTermination()

/*
-------------------------------------------
Batch: 2
-------------------------------------------
+------------------------------------------+-----+-----+
|window                                    |word |count|
+------------------------------------------+-----+-----+
|{2022-09-20 21:01:30, 2022-09-20 21:01:40}|hi   |3    |
|{2022-09-20 21:01:40, 2022-09-20 21:01:50}|hi   |6    |
|{2022-09-20 21:01:40, 2022-09-20 21:01:50}|hello|1    |
+------------------------------------------+-----+-----+
*/
```



#### 내결함성 의미 체계

```
종단 간에 정확히 한 번 처리하는 의미 체계를 전달하는 것은 처리에 대해 정확한 과정을 확실히 처리하기 위해
구조화 스트리밍 소스, 출력 싱크, 실행 엔진을 구현하는 구조적 스트리밍 디자인의 핵심 목표 중 하나였음.
따라서 재시작이나 재처리를 통해 모든 종류의 실패를 처리할 수 있음.
모든 스트리밍 소스는 스트림의 읽기 위치를 추적하기 위해 오프셋을 갖는 것으로 가정함.
스파크는 체크 포인팅과 WAL 로그를 사용해 각 트리거에서 처리 중인 데이터의 오프셋 범위를 저장함.
스트리밍 싱크는 재처리를 처리하기 위해 멱등성을 지원하도록 설계됨.
또한 재생 가능한 소스와 멱등성 싱크를 함께 사용해 구조화 스트리밍은 모든 실패 발생 시
정확히 한 번 처리하는 것에 대한 의미를 종단 간에서 보장할 수 있음.
```

