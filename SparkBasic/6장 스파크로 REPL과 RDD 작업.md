# 6장 스파크로 REPL과 RDD 작업

## 1. 스파크에 대해 깊이 살펴보기

```
스파크는 우아하고 표현력이 풍부한 개발 API를 갖춘 빠른 인메모리 데이터 처리 엔진임.
또한 개발 API를 통해 데이터 워커 노드가 스트리밍 머신 러닝이나
데이터셋에 대해 빠른 대화식 접근이 필요한 SQL 작업을 효율적으로 실행할 수 있게 함.
스파크는 스파크 코어와 관련 라이브러리로 구성됨.
스파크 코어는 분산 실행 엔진이며, 자바, 스칼라, 파이썬 API는 분산 애플리케이션 개발을 위한 플랫폼을 제공함.

스파크에서 분산 컴퓨팅을 계획하고 수행할 수 있도록 스파크는 스테이지와 태스크를 사용하는 여러 워커 노드에서 job이 실행되게 함.
스파크는 워커 노드의 클러스터에서 실행을 제어하는 드라이버를 포함함.
그리고 드라이버는 모든 워커 노드뿐 아니라 현재 각 워커 노드가 수행하는 작업을 추적함.
	- 드라이버 : 드라이버 프로그램에는 애플리케이션, main 프로그램이 들어 있음.
				스파크 셸을 사용하고 있다면 스파크 셸은 드라이버 프로그램이 되고,
				드라이버는 클러스터에 익스큐터를 시작시키고 태스크 실행을 제어함.
	- 익스큐터 : 익스큐터는 클러스터의 워커 노드에서 실행 중인 프로세스임.
				익스큐터 내부에서 개별 태스크나 계산이 실행됨.
				각 워커 노드에 하나 이상의 익스큐터가 존재할 수 있고,
				비슷하게 각 익스큐터 내에 여러 태스크가 존재할 수 있음.
				드라이버가 클러스터 관리자에 연결하여 클러스터 관리자가 익스큐터를 실행할 리소스를 할당하도록 함

스파크 프로그램의 주요 진입점은 SparkContext임.
SparkContext는 드라이버 컴포넌트 내부에 있으며, 스케줄러, 태스크 배포, 조정을 실행하는 코드와 함께 클러스터에 대한 커넥션을 의미함.
드라이버 프로그램을 시작하면 커맨드는 SparkContext를 통해 클러스터에 전달되고, 여러 익스큐터에서 해당 job을 실행함.
실행이 완료되면 드라이버 프로그램은 job을 완료시킴. SparkContext는 재사용될 수 있음.

클러스터에서 SparkContext는 RDD, Accumulator, Broadcast 변수를 생성할 때 사용할 수 있음.
JVM/자바 프로세스당 하나의 SparkContext만 활성화할 수 있음.
새로운 SparkContext를 생성하기 전에 활성화된 SparkContext에 stop을 호출해야 함.

드라이버는 코드를 파싱하고 실행될 익스큐터에 바이트 레벨 코드를 직렬화함.
계산을 수행할 때 인메모리 처리를 사용해 각 노드별로 로컬 레벨에서 실제로 계산이 수행됨.
코드를 파싱하고 실행 계획을 세우는 과정은 드라이버 프로세스에 의해 구현되는 핵심 요소임.

드라이버 프로세스는 분산 처리 프레임워크를 사용해 실행할 코드에 대한 태스크의 DAG를 생성함.
그다음에 DAG는 익스큐터를 실행하기 위한 자원에 대해 클러스터 매니저와 통신함으로써
태스크 스케줄러에 의해 실제 스테이지와 태스크에서 실행됨.
DAG는 job을 의미하며, job은 스테이지라 부르는 부분집합으로 나눌 수 있고,
각 스테이지는 태스크로 실행됨(태스크마다 하나의 코어를 사용함)
스테이지 개수와 스테이지 구성은 연산의 종류에 따라 결정됨.
일반적으로 모든 트랜스포메이션은 이전과 같은 스테이지에 있지만,
리듀스나 셔플과 같은 모든 태스크는 항상 새로운 실행 스테이지를 생성함.
태스크는 스테이지의 일부이며, 익스큐터의 연산을 실행하는 코어와 직접적으로 관련돼 있음.

얀이나 메소스를 클러스터 관리자로 사용하면 얀 동적 스케줄러를 사용할 수 있음.
해당 스케줄러는 더 많은 태스크가 필요하면 익스큐터 개수를 늘릴 수 있고 유휴 익스큐터를 종료시킬 수 있음.

드라이버는 전체 실행 프로세스의 내결함성을 관리함.
드라이버에 의해 잡이 종료될 때 파일, 데이터베이스, 콘솔로 출력이 저장될 수 있음.
따라서 드라이버 프로세스는 익스큐터, 스테이지, 태스크처럼 사용된 자원을 모니터링하고 전체 실행 프로세스를 관리하며,
모든 자원이 계획대로 잘 동작하는지 확인하고 익스큐터 노드 또는 전체 익스큐터 노드에서 태스크 실패와 같은 여러 장애 상황에서 복구됨.

드라이버 프로그램 자체 코드는 모든 변수와 객체를 포함해 완전히 직렬화가 가능해야 함.
흔히 볼 수 있는 에러는 직렬화가 가능하지 않거나 블록 외부의 전역 변수를 포함할 때 발생하는 에러임.
```



## 2. 스파크 배포 모드

### 스파크 독립형

```
스파크 독립형은 얀이나 메소스와 같은 외부 스케줄러에 의존하지 않고 내장된 스케줄러를 사용함.
독립형 모드로 스파크를 설치하려면 클러스터의 모든 장비에 스파크 바이너리 설치 패키지를 복사해야 함.

독립형 모드에서 클라이언트는 spark-submit 또는 스파크 셸을 통해 클러스터와 상호 작용할 수 있음.
두 경우 모두 드라이버는 스파크 마스터 노드와 통신해 워커 노드를 얻음.
그리고 워커 노드의 익스큐터는 제출된 애플리케이션을 실행함.

n 개의 스레드를 가진 로컬 장비를 마스터로 지정하는 기본 셸 커맨드
	spark-shell --master local[n]
	
지정된 스파크 마스터에 연결하는 로컬 장비의 기본 셸 커맨드
	spark-shell --master spark://<IP>:<PORT>

클라이언트 모드를 사용해 얀 클러스터에 연결하는 로컬 장비의 기본 셸 커맨드
	spark-shell --master yarn --deploy-mode client
	
클러스터 모드를 사용해 얀 클러스터에 연결하는 로컬 장비의 기본 셸 커맨드
	spark-shell --master yarn --deploy-mode cluster
```



### YARN 기반 스파크

```
YARN 모드의 클라이언트는 얀 리소스 관리자와 통신하고 스파크를 실행할 수 있는 컨테이너를 얻음.
작은 스파크 클러스터와 같이 해당 컨테이너를 사용자에게 전용으로 배포하는 것처럼 생각.

YARN을 사용해 실행하는 경우 스파크는 클라이언트 모드 또는 클러스터 모드로 실행할 수 있음
```

###### YARN 클라이언트 모드

```
얀 클라이언트 모드에서 드라이버는 클러스터 외부의 특정 노드(일반적으로 클라이언트가 있는 노드)에서 실행됨.
드라이버는 먼저 스파크 job을 실행하기 위해 리소스를 관리하는 리소스 관리자에게 요청함.
리소스 관리자는 특정 컨테이너를 할당하고 드라이버에 응답함.
그다음 드라이버는 컨테이너에서 스파크 애플리케이션 마스터를 실행함.
그리고 스파크 애플리케이션 마스터는 리소스 관리자가 할당한 컨테이너에 익스큐터를 생성함.
얀 컨테이너는 노드 관리자가 제어하는 클러스터에서 모든 노드에 존재할 수 있음.
```

###### YARN 클러스터 모드

```
얀 클러스터 모드에서 드라이버는 클러스터의 특정 노드에서 실행됨(일반적으로 애플리케이션 마스터가 있는 위치)
클라이언트는 먼저 스파크 잡을 실행하기 위해 리소스를 관리자에게 요청함.
리소스 관리자는 특정 컨테이너를 할당하고 클라이언트에게 알려줌.
그다음 클라이언트는 코드를 클러스터에 제출하고 드라이버와 스파크 애플리케이션 마스터를 컨테이너에 실행함.
드라이버는 애플리케이션 마스터와 스파크 애플리케이션 마스터를 함께 실행시킨 후 리소스 관리자가 할당한 컨테이너에 익스큐터를 생성함.
얀 컨테이너는 노드 관리자가 제어하는 클러스터의 모든 노드에 존재할 수 있음.
```



### 메소스 기반의 스파크

```
드라이버는 메소스 마스터와 통신하고 익스큐터를 실행하는 데 필요한 리소스를 할당함.
드라이버는 딕스큐터와 통신해서 job을 실행함. 메소스 드라이버는 먼저 마스터와 통신한 후
모든 메소스 워커 노드에 컨테이너의 요청을 보냄.

여러 컨테이너가 스파크 job에 할당되면 드라이버는 익스큐터를 시작한 다음 익스큐터에서 애플리케이션 코드를 실행함.
스파크 job이 완료되고 드라이버가 종료되면 메소스 마스터는 종료 알림을 받음.
메소스 워커 노드에 있는 컨테이너 형태의 모든 리소스가 회수됨.
```



### 쿠버네티스 기반 스파크

```
쿠버네티스 기반에 스파크 애플리케이션이 동작하려면 스파크 2.3, 쿠버네티스 1.6 이상이어야 하며,
쿠버네티스 DNS 기능이 활성화돼야 함.

spark-submit은 직접 쿠버네티스 클러스터에 스파크 애플리케이션을 제출하는 데 사용할 수 있음.

제출 메커니즘
	- 스파크는 쿠버네티스 pod 내에서 작동하는 스파크 드라이버를 생성함.
	- 드라이버는 쿠버네티스 pod 내에서 실해오디는 익스큐터를 생성하고 익스큐터와 커넥션을 맺은 후 애플리케이션 코드를 실행함.
	- 애플리케이션이 완료되먼 익스큐터 pod이 종료되고 정리됨.
		드라이버 pod은 로그를 유지하는데, 결국 가비지 컬렉션 되거나 수동으로 로그가 정리할 때까지
		쿠버네티스 API에서는 '완료' 상태로 유지됨.
		완료 상태에서 드라이버 pod은 계산하거나 메모리 자원을 사용하지 않음.
		드라이버 및 익스큐터 pod 스케줄링은 쿠버네티스가 처리함.
		드라이버와 익스큐터 pod은 노드 선택자를 통해 사용 가능한 노드 중 일부에서 설정 속성을 사용해 스케줄링할 수 있음.
```



## 3. 트랜스포메이션

```
트랜스포메이션은 입력 엘리먼트 분리, 엘리먼트 필터링, 일종의 계산 수행과 같은 RDD 엘리먼트를 변경함.
시퀀스에서 여러 트랜스포메이션을 수행할 수 있음. but, 트랜스포메이션은 계획 중에는 실행이 일어나지 않음.
DAG에 트랜스포메이션을 추가하고 드라이버가 데이터를 요청할 때만 해당 DAG가 실제로 실행됨(lazy evaluation).

기존 RDD의 각 엘리먼트에 트랜스포메이션 로직을 적용해 기존 RDD에서 새로운 RDD를 생성함.
일부 트랜스포메이션 함수에는 엘리먼트 분할, 엘리먼트 제외, 일종의 계산 수행이 포함됨.
여러 트랜스포메이션을 여러 번 수행할 수 있음. 그러나 계획 중에는 트랜스 포메이션이 실행되지 않음.
```



### 트랜스포메이션의 4가지 범주

#### 일반 트랜스포메이션

```
일반 트랜스포메이션은 대부분의 일반적인 사용 사례를 처리하고
트랜스포메이션 로직을 기존 RDD에 적용해 새로운 RDD를 생성하는 트랜스포메이션 함수.
집계, 필터 등의 일반적인 연산.
```

###### map

```
map(func)

원본의 각 엘리먼트에 func 함수를 적용해서 구성된 새로운 분산 데이터셋 리턴

map 메서드 시그니처
class RDD[T] {
	def map[U](f: (T) => U): RDD[U]
}
T -> U로 타입 변경이 일어날 수도 있음.
```

###### filter

```
filter(func)

원본의 각 엘리먼트에 func 함수를 적용해 true를 리턴하는 엘리먼트를 선택해 새로운 데이터셋 리턴
```

###### flatMap

```
flatMap(func)

맵과 같지만 각 입력 엘리먼트는 0개 이상의 출력 엘리먼트로 매핑될 수 있음
그래서 func는 단일 엘리먼트가 아닌 Seq를 리턴해야 함
함수가 반환한 배열의 중첩 구조를 한 단계 제거하고 모든 배열의 요소를 단일 컬렉션으로 병합함.

def flatMap[U](f: (T) => TraversableOnce[U]): RDD[U]
```

###### groupByKey

```
groupByKey([numTasks])

(K, V) 쌍의 데이터셋을 호출했을 때 (K, Iterable<V>) 쌍의 데이터셋을 리턴

모든 키에 대해 합계 또는 평균과 같은 집계를 수행하기 위해 그룹 연산을 수행하려면
reduceByKey 또는 aggregateByKey가 훨씬 성능이 좋을 것임.

기본적으로 결과의 병렬화 레벨은 부모 RDD의 파티션 개수에 의존함.
선택적으로 numTasks 파라미터를 전달해 태스크 개수를 설정할 수 있음.
```

###### sortByKey

```
sortByKey([ascending], [numTasks])

K가 순서대로 구현된 (K, V) 쌍의 데이터셋에서 호출될 때 boolean 오름차순 파라미터에 지정된 대로
오름차순 또는 내림차순으로 키가 정렬된 (K, V) 쌍의 데이터셋을 리턴
```

###### mapPartitions

```
mapPartitions(func)

맵과 같지만 RDD의 각 파티션에 개별적으로 동작함.
그래서 RDD에 타입 T가 실행될 때 func는 Iterator<T> => Iterator<U>가 되어야 함.
```

###### mapPartitionsWithIndex

```
mapPartitonsWithIndex(func)

mapPartition과 같지만 파티션의 인덱스를 표현하는 정수 값을 가진 func를 제공함.
그래서 RDD에 타입 T가 실행될 때 func는 (Int, Iterator<T>) => Iterator<U>가 되어야 함.
```

###### distinct

```
distinct([numTasks])

원본 데이터셋에서 distinct 엘리먼트를 포함한 새로운 데이터셋을 리턴
```

---



#### 수학/통계 트랜스포메이션

```
일부 통계 기능을 처리하고 기존 RDD에 대한 수학 또는 통계 연산을 적용해 새로운 RDD 생성
샘플링은 수학/통계 트랜스포메이션의 좋은 예
```

###### sample

```
sample([withReplacement: Boolean], fraction: Double, seed: Long = Utils.random.nextLong): RDD[T]

데이터를 샘플링함.

withReplace는 같은 요소가 여러 번 샘플링될 수 있는지 지정.
false로 지정하면 한 번 샘플링된 요소는 메서드 호출이 끝날 때까지 다음 샘플링 대상에서 제외됨.
즉, 데이터가 제자리로 복원되지 않고 제거됨(비복원 샘플링)

fraction은 복원 샘플링에서는 각 요소가 샘플링될 횟수의 기대값(0 이상의 값)을 의미함.
비복원 샘플링에서는 각 요소가 샘플링될 기대 확률(0 ~ 1 사이의 부동소수점 숫자)을 의미함.
샘플링은 어디까지나 확률이므로 항상 같은 결과가 나올 수는 없음.

seed는 난수 생성에 사용. 같은 시드는 항상 같은 유사 난수를 생성하기 때문에 프로그램을 테스트하는 데 유용.
sample 메서드는 내부적으로 java.util.Random에 기반한 scala.util.Random을 사용함.
seed 인자의 기본 값을 Utils.random.nextLong으로 정의함.
```

###### reduceByKey

```
reduceByKey(func, [numTasks])

(K, V) 쌍의 데이터셋에서 호출되면 각 키의 값에 주어진 reduce 함수(타입은 (V,V) => V)를 사용해
집계되는 (K, V) 쌍의 데이터셋 리턴.
groupByKey처럼 선택적으로 두 번째 파라미터에 reduce 태스크 개수를 전달할 수 있음.
```

###### aggregateByKey

```
aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])

(K, V) 쌍의 데이터셋에서 호출될 때 주어진 조합 함수(combOp)와 순수 0값(zeroValue)을 사용해
각 키의 값이 집계되는 (K, U) 쌍의 데이터셋 리턴.
불필요한 할당을 피하면서 입력 값 타입과 다른 집계된 값 타입을 허용함.
```

###### sampleByKey

###### randomSplit

---



#### 집합 이론/관계형 트랜스포메이션

```
데이터셋의 조인과 코그룹같은 관계형 대수 함수와 같은 트랜스포메이션 처리
집합 이론/관계형 함수는 기존 RDD에 집합 이론/관계형 트랜스포메이션 로직을 적용해 새로운 RDD 생성
```

###### cogroup

```
cogroup(otherDataset, [numTasks])

(K, V)와 (K, W) 타입의 데이터셋에서 호출되면
(K, (Iterable<V>, Iterable<W>)) 튜플의 데이터셋 리턴. 해당 연산을 groupWith라고도 함.
```

###### join

```
join(otherDataset, [numTasks])

(K, V)와 (K, W) 타입의 데이터셋에서 호출되면
각 키의 모든 엘리먼트 쌍으로 (K, (V, W)) 쌍의 데이터셋 리턴.
외부 조인(outer join)은 leftOuterJoin, rightOuterJoin, fullOuterJoin이 있음.
```

###### cartesian

```
cartesian(otherDataset)

T와 U 타입의 데이터셋에서 호츌되면 (T, U) 쌍(모든 엘리먼트의 쌍)의 데이터셋 리턴
```

###### union

```
union(otherDataset)

원본 데이터셋의 엘리먼트와 파라미터를 합집합 연산으로 얻은 새로운 데이터셋 리턴
```

###### intersection

```
intersection(otherDataset)

원본 데이터셋의 엘리먼트와 파라미터를 교집합 연산으로 얻은 새로운 데이터셋을 리턴
```

###### subtractByKey

---



#### 데이터 구조 기반 트랜스포메이션

```
RDD의 기본 데이터 구조, RDD의 파티션에서 동작하는 트랜스포메이션 함수.
데이터 구조 기반 트랜스포메이션을 사용하면 RDD의 엘리먼트/데이터를 직접 다루지 않고도 파티션에서 직접 작업할 수 있음.

데이터 구조 기반 트랜스포메이션은 간단한 프로그램 이외에 클러스터의 파티션을 더 많이 제어하고
클러스터의 파티션을 배포해야 하는 스파크 프로그램에서는 필수.
일반적으로 클러스터 상태, 데이터 크기, 정확한 사용 사례 요구 사항에 따라
데이터 파티션을 재배포해 성능을 향상시킬 수 있음.
```

###### repartition

```
repartition(numPartitions)

RDD의 데이터를 무작위로 섞어 많거나 적은 파티션을 생성하고 해당 파티션을 통해 균형을 맞춤.
이는 항상 네트워크를 통해 모든 데이터를 셔플링함.
```

###### coalesce

```
coalesce(numPartitions)

RDD의 파티션 개수를 numPartitions로 줄임.
큰 데이터셋을 필터링한 후 동작 중인 연산을 더 효율적으로 실행하고 싶을 때 유용.
```

###### repartitionAndSortWithinPartitions

```
repartitionAndSortWithinPartitions(partitioner)

주어진 파티셔너에 따라 RDD를 다시 파티셔닝함.
각 결과 파티션 영역 내에서 해당 키로 레코드를 정렬함.
이는 정렬을 셔플 시스템에 넣을 수 있기 때문에
repartition을 호출하고 각 파티션에서 레코드를 정렬하는 것보다 더 효율적임.
```

---



#### 기타

###### pipe

```
pipe(command, [envVars])

셸 커맨드를 통해 RDD의 각 파티션을 파이프 처리함.
RDD 엘리먼트는 프로세스의 표준 입력으로 써지고, 표준 출력으로 출력되는 라인은 문자열의 RDD로 리턴됨
```

---



## 4. 액션

```
액션은 실제로 계산이 수행되는 연산.
액션 연산이 발생할 때까지 스파크 프로그램의 실행 계획은 DAG 형태로 만들어지며 아무것도 수행하지 않음.
실행계획에는 여러 가지 트랜스포메이션이 존재할 수 있지만 액션을 수행할 때까지는 어떠한 변화도 없음.

코드 블록과 함수를 실행함으로써 데이터가 구체화될 수 있게 생성된 트랜스포메이션의 전체 DAG를 실행함.
DAG가 명세한 대로 모든 연산이 실행됨.
```



### 1) 액션의 두 가지 종류

#### 드라이버

```
액션 중 하나로서 개수 또는 키 개수를 얻는 등의 드라이버 동작.
이런 액션 각각은 원격 익스큐터에서 계산을 수행하고 데이터를 다시 드라이버로 가져옴.
큰 데이터셋에 대한 액션이 드라이버에서 사용 가능한 메모리를 쉽게 넘어서는 문제를 갖고 있기 때문에
드라이버 기반 액션을 사용할 때 신중하게 사용해야 함.
```



#### 분산

```
액션 중 하나로서 분산 액션으로 클러스터의 노드에서 실행됨.
분산 액션의 예는 saveAsTextfile을 들 수 있음. 좋은 분산 특성을 갖고 있는 가장 일반적인 액션 연산.
```



### 2) 액션 함수 목록

###### reduce(func)

```
함수 func(두 개의 파라미터를 사용하고 하나의 결과를 리턴)를 사용해 데이터셋의 엘리먼트 집계.
함수는 교환 가능하고 결합 가능해야 병렬로 정확하게 계산할 수 있음.
```

###### collect()

```
드라이버 프로그램에서 데이터셋의 모든 엘리먼트를 배열로 리턴.
해당 함수는 대개 데이터의 충분히 작은 부분집합을 리턴하는 필터 또는 기타 연산을 호출한 후에 유용.
```

###### count()

```
데이터셋의 엘리먼트 개수를 리턴
```

###### first()

```
데이터셋의 첫 번째 엘리먼트를 리턴(take(1)과 비슷)
```

###### take(n)

```
지정된 개수의 요소를 모을 때까지 RDD의 파티션(클러스터의 여러 노드에 저장된 데이터의 일부분)을 하나씩 처리해 결과를 반환.
파티션을 하나씩 처리한다는 것은 결국 연산이 전혀 분산되지 않는다는 의미.
여러 파티션의 요소를 빠르게 가져오고 싶다면 드라이버의 메모리를 넘지 않도록 요소 개수를 적당히 줄이고 collect 연산자 사용.
```

###### takeSample([withReplacement], num, [seed])

```
sample과 takeSample의 차이점은 두 가지.

takeSample 메서드의 두 번째 인자가 샘플링 결과로 반환될 요소의 개수를 지정하는 정수형 변수.
(요소 개수의 기대값이 아닌 항상 정확한 개수로 샘플링함)

sample이 변환 연산자인 반면 takeSample은 collect와 마찬가지로 배열을 반환하는 액션 연산자
```

###### takeOrdered(n, [ordering])

```
자연적인 순서 또는 사용자 지정 비교기(comparator)를 사용해 RDD의 처음 n개 엘리먼트 리턴
```

###### saveAsTextfile(path)

```
데이터셋의 엘리먼트를 로컬 파일 시스템, HDFS 또는 기타 하둡을 지원하는
파일 시스템의 지정된 디렉터리에 텍스트 파일(또는 텍스트 파일 셋)로 생성
스파크는 각 엘리먼트의 toString을 호출해 해당 파일을 파일의 텍스트 라인으로 변환함.
```

###### saveAsSequenceFile(path)

```
데이터셋의 엘리먼트를 로컬 파일 시스템, HDFS 또는 기타 하둡을 지원하는
파일 시스템의 지정된 경로에 하둡 시퀀스 파일로 작성.
하둡의 Writable 인터페이스를 구현하는 키-값 쌍의 RDD에서 사용할 수 있음.
스칼라에서는 암시적으로 Writable로 변환할 수 있는 타입에서도 사용할 수 있음
(스파크에서는 Int, Double, String 등의 기본 타입에 대한 변환을 포함함)
```

###### saveAsObjectFile(path)

```
자바 직렬화를 사용해 간단한 포맷으로 데이터셋의 엘리먼트를 저장함.
SparkContext.objectFile을 사용해 로드할 수 있음.
```

###### countByKey()

```
타입 (K, V)의 RDD에서만 사용할 수 있음. 각 키의 개수와 (K, Int) 쌍의 해시 맵 리턴
```

###### foreach(func)

```
데이터셋의 각 엘리먼트마다 func 함수 실행.
이는 accumulators 업데이트 또는 외부 저장소 시스템과의 상호작용과 같은 부수 효과로 일반적으로 수행됨.

foreach 바깥에서 accumulators가 아닌 변수를 수정하면 정의되지 않는 동작이 발생할 수 있음.
```

---



## 5. 캐싱

### 1) 저장소 레벨에 사용할 수 있는 값

###### MEMORY_ONLY

```
RDD를 JVM의 역직렬화된 자바 객체로 저장.
메모리 공간에 RDD를 만들 수 없으면 일부 파티션은 캐싱되지 않고 필요할 때마다 매번 다시 계산. 기본 레벨.
```

###### MEMORY_AND_DISK

```
RDD를 JVM의 역직렬화된 자바 객체로 저장.
메모리 공간에 RDD를 만들 수 없으면 디스크에 맞지 않는 파티션을 저장하고 필요할 때마다 읽음.
```

###### MEMORY_ONLY_SER

```
직렬화된 자바 객체(파티션당 1바이트 배열)로 RDD를 저장함.
MEMORY_ONLY_SER는 일반적으로 빠른 serializer를 사용할 때 역직렬화된 객체보다 공간 효율적임.
그러나 읽을 때는 CPU를 많이 사용함.
```

###### MEMORY_AND_DISK_SER

```
MEMORY_ONLY_SER와 비슷하지만 매번 필요할 때마다 계산하지 않고 메모리와 디스크에 들어가지 않는 파티션을 저장.
```

###### DISK_ONLY

```
디스크에만 RDD 파티션 저장
```

###### MEMORY_ONLY_2, MEMORY_AND_DISK_2 등

```
이전 레벨과 동일하지만 두 클러스터 노드의 각 파티션을 복제함.
```

###### OFF_HEAP

```
MEMORY_ONLY_SER와 비슷하지만 오프 힙 메모리에 데이터를 저장함.
이전에 미리 오프 힙 메모리가 활성화되어 있어야 함.
```



### 2) 상황별 저장소 레벨 선택

```
RDD가 메모리에 저장할 수 있으면 실행 성능이 가장 빠른 MEMORY_ONLY 사용

MEMORY_ONLY_SER를 사용하면 객체를 더 작게 만들기 위해 직렬화 가능한 객체가 저장됨.

계산이 비싸지 않으면 DISK를 사용하지 않음.

추가적으로 필요한 메모리를 아낄 수 있다면 최상의 내결함성을 지닌 복제 저장소를 사용.
해당 저장소는 최상의 가용성을 보장함으로써 손실된 파티션을 재계산하지 않게 함
```