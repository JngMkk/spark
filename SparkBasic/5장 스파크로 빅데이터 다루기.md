# 5장 스파크로 빅데이터 다루기

## 1. 하둡을 이용한 분산 컴퓨팅

```
아파치 하둡 프레임워크는 자바로 작성된 오픈소스 소프트웨어 프레임워크.
아파치 하둡 프레임워크가 제공하는 두 가지 주요 영역은 스토리지와 처리.
스토리지의 경우 하둡 프레임워크는 구글 파일 시스템을 기반으로 한 하둡 분산 파일 시스템(HDFS)을 사용함.
처리의 경우 맵리듀스에 의존함.
```

### 하둡 분산 파일 시스템(HDFS)

```
HDFS는 자바로 구현된 소프트웨어 기반의 파일 시스템이고 네이티브 파일 시스템기반 위에서 동작함.
HDFS의 기본 개념은 파일 전체를 처리하는 대신 파일을 블록(일반적으로 128MB)으로 분할한다는 것.
이는 배포, 복제, 에러 복구, 더 중요하게는 여러 물리 서버를 사용한 블록 분산 처리와 같은 많은 기능을 사용할 수 있게 함.
HDFS는 내결함성과 장애 복구 기능을 갖춘 스토리지 시스템을 제공함.
HDFS에는 네임 노드와 데이터 노드라는 두 가지 주요 컴포넌트가 있음.
네임노드는 파일 시스템의 모든 내용에 대한 메타데이터를 포함함.
데이터 노드는 네임 노드에 연결하고 파일 시스템의 내용과 관련된 모든 메타데이터 정보를 포함하는 네임 노드에 의존.
네임 노드가 어떠한 정보도 알지 못한다면 데이터 노드는 HDFS를 읽고 저장하기를 원하는 클라이언트에 어떠한 서비스도 제공할 수 없음.

네임 노드와 데이터 노드는 JVM 프로세스이기 때문에
자바를 지원하는 모든 물리 서버에서는 네임 노드 또는 데이터 노드 프로세스를 실행할 수 있음.

클러스터에 단일 네임 노드가 존재하면 시스템의 아키텍처는 크게 단순함.
네임 노드는 모든 HDFS 메타데이터와 클라이언트의 중재자이자 저장소이며,
데이터 읽기/저장을 원하는 모든 클라이언트는 먼저 메타데이터 정보를 갖고 있는 네임 노드에 접속함.

HDFS는 대부분의 다른 파일 시스템과 유사한 디렉터리와 파일을 가진 전통적인 계층적 파일 시스템을 지원함.
파일과 디렉터리를 생성, 이동, 삭제할 수 있음.
네임 노드는 파일 시스템 네임스페이스를 유지하고 모든 변경 사항과 파일 시스템의 상태를 기록함.
애플리케이션은 HDFS에 의해 유지돼야 하는 파일의 복제본 수를 지정할 수 있고 정보는 네임 노드에도 저장됨.

HDFS는 데이터 노드로 구성된 큰 클러스터에서 여러 물리 서버로 구성된 분산 방식을 사용해 매우 큰 파일을 안정적으로 저장하게 설계됨.
복제, 내결함성, 분산 컴퓨팅을 처리하기 위해 HDFS는 각 파일을 일련의 블록으로 저장함.

네임 노드는 블록 복제와 관련된 모든 결정을 내림.
해당 결정은 주로 하트 비트 간격마다 주기적으로 수신되는 클러스터의 각 데이터 노드에서 보낸 블록 리포트에 따라 달라짐.
블록 리포트는 데이터 노드의 모든 블록 리포트를 포함하며, 네임 노드는 해당 리포트를 메타데이터 저장소에 저장함.

네임 노드는 모든 메타데이터를 메모리에 저장하고 HDFS에서 읽고 쓰는 클라이언트의 모든 요청을 처리함.
그러나 네임 노드가 HDFS에 대한 모든 메타데이터를 유지, 관리하는 마스터 노드이기 때문에
일관되고 안정적인 메타데이터 정보를 유지, 관리하는 것이 중요함. 메타데이터 정보가 손실되면 HDFS 콘텐츠에 접근할 수 없음.

메타데이터 손실을 막기 위해 네임 노드는 Edit Log라는 트랜잭션 로그를 사용함.
Edit Log는 파일 시스템의 메타데이터에서 발생하는 모든 변경 사항을 기록함.
Edit Log를 변경하는 새로운 파일을 생성한다는 것은 파일을 옮기거나 이름을 변경하거나 파일을 삭제하는 것을 의미함.
파일과 파일 시스템 속성에 대한 블록 매핑을 포함한 전체 파일 시스템 네임스페이스는 FsImage라는 파일에 저장됨.
또한 네임 노드는 모든 정보를 메모리에 유지함.
네임 노드가 시작되면 Edit Log가 로드되고 HDFS를 설정하기 위해 FsImage가 초기화됨.

그러나 데이터 노드는 HDFS에 대해 전혀 모르며, 저장된 데이터 블록에만 순수하게 의존함.
그렇기 때문에 데이터 노드는 모든 연산을 수행하기 위해 네임 노드에 전적으로 의존하게 됨.
클라이언트가 파일을 읽거나 파일에 저장하려 할 때 네임 노드가 연결할 데이터 노드를 클라이언트에게 알려주게 됨.
```



### HDFS 고가용성

```
HDFS는 네임 노드인 마스터와 데이터 노드로 구성된 마스터-워커 클러스터임.
클러스터에 단일 장애점(SPOF, 네임 노드가 어떤 이유로 동작이 중지되면 전체 클러스터를 사용할 수 없음)이 있음.
HDFS 1.0은 클러스터를 복구할 수 있는 보조 네임 노드(Secondary Name Node)로 알려진 추가 마스터 노드를 지원함.
파일 시스템의 모든 메타데이터의 복제본을 유지함으로써 이뤄지며, 수동으로 유지 보수 작업을 필요로 하는 고가용성 시스템이 아님.
그리하여 HDFS 2.0은 고가용성 기능(HA)을 추가하게 됨.

HA는 한 네임 노드가 활성이고 다른 노드가 비활성인 액티브-패시브 모드에서 2개의 네임 노드를 사용함으로써 동작함.
기존 네임 노드가 실패하면 비활성화된 네임 노드가 마스터 노드의 역할을 대신함.
```



### HDFS Federation

```
여러 네임 노드를 사용해 파일 시스템 네임스페이스를 분산시키는 방법.
단일 네임 노드를 사용해 전체 클러스터를 관리하고 클러스터의 크기가 커짐에 따라 확장성이 떨어지던 HDFS 1.0과 달리
HDFS Federation은 상당히 큰 클러스터를 지원할 수 있고,
Federation으로 구축된 여러 네임 노드를 사용한 name service 또는 네임 노드를 수평으로 확장할 수 있음.
```



### HDFS 스냅샷

```
하둡 2.0에는 데이터 노드에 저장된 파일 시스템(데이터 블록)의 스냅샷을 생성하는 새로운 기능이 추가됨.
스냅샷을 사용하면 데이터 블록의 네임 노드 메타데이터를 사용해 디렉터리를 복사할 수 있음.
스냅샷 생성은 바로 진행되며, 다른 일반 HDFS 연산과 간섭이 없음.
```



### HDFS 읽기

```
클라이언트는 네임 노드에 연결하고 파일 이름을 사용해서 파일에 대해 요청함.
네임 노드는 파일의 블록 위치를 검색하고 클라이언트에 해당 위치를 리턴함.
그리고 클라이언트는 데이터 노드에 연결하고 필요한 블록을 읽을 수 있음.
데이터 노드에서 읽기를 실패하면 클라이언트는 다른 데이터 노드에서 블록의 복제본을 얻게 됨.
네임 노드는 데이터 전송에 참여하지 않음.
```



### HDFS 저장

```
클라이언트는 네임 노드에 연결하고 네임 노드에게 HDFS에 데이터를 저장할 수 있는지 요청함.
네임 노드는 해당 정보를 검색하고 블록과 블록을 저장할 때 사용되는 데이터 노드, 사용할 복제 전략을 계획함.
네임 노드는 어떤 데이터도 처리하지 않고 클라이언트에게 저장할 곳만 알려줌.
복제 파라미터가 3인 경우 복제 전략을 기반으로 첫 번째 데이터 노드가 블록을 수신하면
네임 노드는 그 데이터 노드에게 데이터를 복제할 다른 위치를 알려줌.
```



### 맵리듀스 프레임워크

```
분산 처리를 수행하기 위해 하둡 프레임워크에서 생성됨.
맵리듀스 프레임워크를 사용하면 분산 애플리케이션을 작성할 수 있으며,
HDFS와 같은 파일 시스템에서 대량의 데이터를 안정성과 내결함성을 유지하며 처리할 수 있음.
데이터를 처리하기 위해 맵리듀스 프레임워크를 사용하고 싶다면 먼저 job을 생성한 후
맵리듀스 프레임워크에서 해당 잡을 실행시켜 필요한 태스크를 수행함.

맵리듀스 작업은 매퍼 태스크가 동작 중인 워커 노드에서 입력 데이터를 병렬로 분할하면서 동작함.
이때 HDFS 레벨이나 매퍼 태스크의 실패에서 발생하는 모든 장애는 내결함성 유지를 위해 자동으로 처리됨.
매퍼 태스크가 완료되면 그 결과는 네트워크를 통해 리듀서 태스크가 실행 중인 다른 시스템으로 복사됨.

맵리듀스 프레임워크는 하나의 리소스 관리자와 여러 노드 관리자로 구성됨.
(일반적으로 노드 관리자는 HDFS의 데이터 노드와 함께 존재함.)
애플리케이션을 실행하려 할 때 클라이언트는 애플리케이션 마스터를 실행한 다음,
컨테이너 형태의 자원을 클러스터에서 얻기 위해 리소스 관리자와 협상을 하게 됨.
리소스 관리자와 애플리케이션 마스터는 일부 컨테이너를 매퍼로 할당하고 다른 컨테이너는 리듀서가 되도록 지정함.
이런 프레임워크는 YARN(Yet Another Resource Negotiator)이라 부름.

맵리듀스 프레임워크는 주로 데이터를 처리하는 방식 때문에 이슈가 발생할 수도 있음.
Hive와 Pig처럼 맵리듀스를 쉽게 사용할 수 있는 기술이 여럿 등장했지만 맵리듀스의 복잡성은 여전히 존재함.
```

###### Hive

- 페이스북에서 만들었고 맵리듀스를 SQL과 비슷한 인터페이스로 사용할 수 있음

###### Pig

- 야후에서 만들었고 맵리듀스를 스크립팅 인터페이스로 사용할 수 있음
- 맵리듀스의 한계를 회피할 수 있는 인메모리 최적화 기능을 제공함

###### 맵리듀스의 제한 사항

- 디스크 기반 처리로 인한 성능 병목 현상
- 일괄 처리는 모든 요구를 충족시키지 못함
- 프로그램 코드가 많고 복잡할 수 있음
- 자원 재사용을 거의 하지 않기 때문에 태스크 스케줄링이 느림
- 실시간 이벤트 처리를 수행할 좋은 방법이 없음
- 머신 러닝은 종종 반복 처리를 하는데 맵리듀스는 해당 작업을 수행하기에 너무 느림



## 2. 아파치 스파크

###### 스파크의 장점

- 가능한 한 인메모리에서 처리하려고 함
- 배치, 실시간 작업에 사용할 수 있는 범용 엔진
- 얀과 메소스와 호환 가능
- HBase, 카산드라, 몽고DB, HDFS, 아마존 S3, 기타 파일 시스템과 데이터 소스와 잘 통합됨



###### 스파크의 기능

- 간단한 API를 통해 여러 노드의 데이터를 투명하게 처리
- 장애를 탄력적으로 처리
- 주로 메모리를 사용하지만 필요에 따라 데이터를 디스크에 저장
- 자바, 스칼라, 파이썬, R, SQL API 지원
- 동일한 스파크 코드를 하둡 얀, 메소스, 클라우드에서 독립형으로 실행할 수 있음

```
통합 분산 컴퓨팅 엔진. 범용 분산 컴퓨팅 플랫폼이라는 점에서 하둡과 유사.
다양한 플랫폼에 연결할 수 있고 스파크 스트리밍, 스파크 ML, 스파크 SQL,
스파크 GraphX 같은 다양한 패러다임을 사용해 다양한 데이터 작업을 처리할 수 있음.
스파크는 데이터 작업자가 스트리밍 머신 러닝을 실행하거나 데이터셋에 대해 빠른 대화식 접근이 필요한 SQL 작업 부하를
효율적으로 실행할 수 있게 풍부한 API를 갖춘 빠른 인메모리 데이터 처리 엔진임.
스파크는 스파크 코어와 관련 라이브러리로 구성됨.
코어는 분산 실행 엔진이고 스파크의 자바, 스칼라, 파이썬 API는 분산 애플리케이션 개발을 위한 플랫폼으로 사용 가능.
스파크 코어 위에 구축된 추가 라이브러리를 통해 스트리밍, SQL, 그래프 처리, 머신 러닝을 구현할 수 있음.

일부 애플리케이션은 스파크를 사용하기에 적합하지 않을 수 있음.
스파크에서는 분산 아키텍처 때문에 처리 시간에 약간의 오버헤드가 필연적으로 발생함.
대량의 데이터를 다룰 때는 무시할 수 있는 수준이지만, 단일 머신에서도 충분히 처리할 수 있는 데이터셋을 다룰 때는
작은 데이터셋의 연산에 최적화된 다른 프레임워크를 사용하는 것이 더 효율적임.
또 스파크는 온라인 트랜잭션 처리(OLTP) 애플리케이션을 염두에 두고 설계되지 않음.
즉, 대량의 원자성 트랜잭션을 빠르게 처리해야 하는 작업에는 스파크가 적합하지 않음.
반면 일괄 처리 작업이나 데이터 마이닝 같은 OLAP 작업에는 적합함.
스파크는 job과 태스크를 시작하는 데 상당한 시간을 소모하기 때문에
대량의 데이터를 처리하는 작업이 아니라면 굳이 스파크를 사용할 필요가 없음.
소량의 데이터를 처리할 때는 스파크 같은 분산 시스템보다 간단한 관계형 데이터베이스나 잘 짜인 스크립트가 훨씬 빠름.

스파크는 스토리지 레이어를 제공하지 않으며, HDFS 또는 아마존 S3 등을 사용함.
따라서 하둡 기술을 스파크로 대체하더라도 신뢰할 수 있는 저장소 레이어를 제공하려면 HDFS가 필요함.
혹은 아파치 쿠두를 사용할 수 있음.
아파치 쿠두는 HDFS의 대안 기술이며, 스파크와 쿠두 저장소 레이어를 통합해 스파크와 하둡 생태계를 더욱 분리함.
하둡과 스파크는 모두 대중적인 빅데이터 프레임워크이지만, 실제 같은 목적을 달성하지 못함.
하둡은 분산 스토리지와 맵리듀스 분산 컴퓨팅 프레임워크를 제공하지만
스파크는 다른 기술이 제공하는 분산 데이터 스토리지에서 동작하는 데이터 처리 프레임워크임.

스파크는 데이터를 처리하는 방식 때문에 일반적으로 맵리듀스보다 훨씬 빠름.
맵리듀스는 디스크 연산을 사용하는 스플릿에서 동작하며, 스파크는 맵리듀스보다 데이터셋 기반 위에서 훨씬 효율적으로 동작함.
스파크는 디스크 기반 계산에 주로 의존하기보다 효율적인 오프라인 힙 인메모리 처리 방식을 적용함으로써 성능이 향상됨.

스파크 스택에는 3개의 레이어가 있음.
맨 아래 레이어는 독립형, 얀, 메소스를 사용할 수 있는 클러스터 관리자.(로컬 모드에선 사용할 필요 없음)
클러스터 관리자 위에 위치한 스파크 코어 레이어는 작업 기본 설정을 수행하고 저장소와 상호작용할 수 있는 모든 기본 API 제공함.
상단에는 대화식 쿼리를 제공하는 스파크 SQL, 실시간 분석을 위한 스파크 스트리밍,
머신 러닝을 위한 스파크 ML, 그래프 처리를 위한 스파크 GraphX 같이 스파크 코어 위에서 실행되는 모듈이 있음.
```

![lnsp_0101](https://user-images.githubusercontent.com/87686562/190848086-189c7fdc-546f-430d-8ae2-9cb4f27314d2.png)



### 스파크 코어

```
스파크 코어는 다른 모든 기능들이 기반으로 하는 스파크 플랫폼의 기본 실행 엔진.
스파크 코어는 job 실행에 필요하며 다른 컴포넌트에서 필요한 기본 스파크 기능을 제공함.
외부 스토리지 시스템에서 인메모리 컴퓨팅과 참조 데이터셋을 제공함.
스파크 코어에서 가장 중요한 것은 RDD(Resilient Distributed Dataset)임.
RDD는 분산 데이터 컬레션(데이터셋)을 추상화한 객체로 데이터셋에 적용할 수 있는 연산 및 변환 메서드를 함께 제공함.
RDD는 노드에 장애가 발생해도 데이터셋을 재구성할 수 있는 복원성을 갖춤.

스파크 코어에는 HDFS, 아마존 S3, Hbase, 카산드라, 관계형 데이터베이스 등과 같은 다양한 파일 시스템에 접근할 수 있는 로직이 포함돼 있음.
또 Broadcast 변수와 Accumulator 변수를 사용해 컴퓨팅 노드 간에 정보를 공유할 수 있음.
이외에도 네트워킹, 보안, 스케줄링뿐만 아니라 분산 컴퓨팅에서 필요한
고확장성, 내결함성 플랫폼을 구축할 수 있는 데이터 셔플링과 같은 기본적인 기능을 제공함.
```



## 스파크 SQL

```
SchemaRDD라는 새로운 데이터 추상화를 도입해 구조화 데이터와 반구조화 데이터를 지원함.
스파크 SQL은 스파크와 하이브 QL에서 지원하는 SQL 부분집합을 사용해 분산된 구조화 데이터셋을 조작하는 기능을 제공함.
스파크 SQL은 텅스텐 프로젝트의 일부로서 데이터 프레임과 데이터셋을 통해 구조화된 데이터 처리를 훨씬 단순하게 처리함.
또한 다양한 구조화된 포맷, 데이터 소스, 파일, Parquet, DB, 하이브, HDFS, S3 등의 데이터 읽기/저장 기능을 지원함.
모든 작업을 최적화해 속도를 향상시키기 위해 카탈리스트라고 하는 쿼리 최적화 프레임워크를 제공함.
또한 쓰리프트 서버를 포함함. 외부 시스템에서 쓰리프트 서버를 사용해 JDBC와 ODBC 프로토콜로 데이터를 쿼리할 수 있음.
```

